<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[lilaiqun]]></title>
  <link href="blog.lilaiqun.com/atom.xml" rel="self"/>
  <link href="blog.lilaiqun.com/"/>
  <updated>2019-10-09T21:16:54+08:00</updated>
  <id>blog.lilaiqun.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[如何练好SQL]]></title>
    <link href="blog.lilaiqun.com/15706131641039.html"/>
    <updated>2019-10-09T17:26:04+08:00</updated>
    <id>blog.lilaiqun.com/15706131641039.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>摘自 <a href="https://www.cnblogs.com/xiaoyangjia/p/11267191.html">https://www.cnblogs.com/xiaoyangjia/p/11267191.html</a></p>
</blockquote>

<p>博主负责的项目主要采用阿里云数据库MySQL，最近频繁出现慢SQL告警，执行时间最长的竟然高达5分钟。导出日志后分析，主要原因竟然是<strong>没有命中索引</strong>和<strong>没有分页处理</strong>。其实这是非常低级的错误，我不禁后背一凉，团队成员的技术水平亟待提高啊。改造这些SQL的过程中，总结了一些经验分享给大家，如果有错误欢迎批评指正。</p>

<h2 id="toc_0">MySQL性能</h2>

<h3 id="toc_1">1.最大数据量</h3>

<p>  抛开数据量和并发数，谈性能都是耍流氓。MySQL没有限制单表最大记录数，它取决于操作系统对文件大小的限制。</p>

<table>
<thead>
<tr>
<th>文件系统</th>
<th>单文件大小限制</th>
</tr>
</thead>

<tbody>
<tr>
<td>FAT32</td>
<td>最大4G</td>
</tr>
<tr>
<td>NTFS</td>
<td>最大64GB</td>
</tr>
<tr>
<td>NTFS5.0</td>
<td>最大2TB</td>
</tr>
<tr>
<td>EXT2</td>
<td>块大小为1024字节，文件最大容量16GB；块大小为4096字节，文件最大容量2TB</td>
</tr>
<tr>
<td>EXT3</td>
<td>块大小为4KB，文件最大容量为4TB</td>
</tr>
<tr>
<td>EXT4</td>
<td>理论可以大于16TB</td>
</tr>
</tbody>
</table>

<p>《阿里巴巴Java开发手册》提出单表行数超过500万行或者单表容量超过2GB，才推荐分库分表。性能由综合因素决定，抛开业务复杂度，影响程度依次是硬件配置、MySQL配置、数据表设计、索引优化。500万这个值仅供参考，并非铁律。博主曾经操作过超过4亿行数据的单表，分页查询最新的20条记录耗时0.6秒，SQL语句大致是<code>select field_1,field_2 from table where id &lt; #{prePageMinId} order by id desc limit 20，prePageMinId</code> 是上一页数据记录的最小ID。虽然当时查询速度还凑合，随着数据不断增长，有朝一日必定不堪重负。分库分表是个周期长而风险高的大活儿，应该尽可能在当前结构上优化，比如升级硬件、迁移历史数据等等，实在没辙了再分。对分库分表感兴趣的同学可以阅读分库分表的基本思想。</p>

<h3 id="toc_2">2.最大并发数</h3>

<p>  并发数是指同一时刻数据库能处理多少个请求，由<code>max_connections</code>和<code>max_user_connections</code>决定。<code>max_connections</code>是指MySQL实例的最大连接数，上限值是16384，<code>max_user_connections</code>是指每个数据库用户的最大连接数。MySQL会为每个连接提供缓冲区，意味着消耗更多的内存。如果连接数设置太高硬件吃不消，太低又不能充分利用硬件。一般要求两者比值超过10%，计算方法如下：<br/>
<code>max_used_connections / max_connections * 100% = 3/100 *100% ≈ 3%</code></p>

<p>查看最大连接数与响应最大连接数：</p>

<pre><code class="language-text">show variables like &#39;%max_connections%&#39;;
show variables like &#39;%max_user_connections%&#39;;
</code></pre>

<p>在配置文件<code>my.cnf</code>中修改最大连接数</p>

<pre><code class="language-text">[mysqld]
max_connections = 100
max_used_connections = 20
</code></pre>

<p>查询耗时0.5秒<br/>
  建议将单次查询耗时控制在0.5秒以内，0.5秒是个经验值，源于用户体验的3秒原则。如果用户的操作3秒内没有响应，将会厌烦甚至退出。响应时间=客户端UI渲染耗时+网络请求耗时+应用程序处理耗时+查询数据库耗时，0.5秒就是留给数据库1/6的处理时间。</p>

<p>实施原则<br/>
  相比NoSQL数据库，MySQL是个娇气脆弱的家伙。它就像体育课上的女同学，一点纠纷就和同学闹别扭(扩容难)，跑两步就气喘吁吁(容量小并发低)，常常身体不适要请假(SQL约束太多)。如今大家都会搞点分布式，应用程序扩容比数据库要容易得多，所以实施原则是数据库少干活，应用程序多干活。</p>

<p>充分利用但不滥用索引，须知索引也消耗磁盘和CPU。<br/>
不推荐使用数据库函数格式化数据，交给应用程序处理。<br/>
不推荐使用外键约束，用应用程序保证数据准确性。<br/>
写多读少的场景，不推荐使用唯一索引，用应用程序保证唯一性。<br/>
适当冗余字段，尝试创建中间表，用应用程序计算中间结果，用空间换时间。<br/>
不允许执行极度耗时的事务，配合应用程序拆分成更小的事务。<br/>
预估重要数据表（比如订单表）的负载和数据增长态势，提前优化。<br/>
数据表设计<br/>
数据类型<br/>
  数据类型的选择原则：更简单或者占用空间更小。</p>

<p>如果长度能够满足，整型尽量使用tinyint、smallint、medium_int而非int。<br/>
如果字符串长度确定，采用char类型。<br/>
如果varchar能够满足，不采用text类型。<br/>
精度要求较高的使用decimal类型，也可以使用BIGINT，比如精确两位小数就乘以100后保存。<br/>
尽量采用timestamp而非datetime。<br/>
类型  占据字节    描述<br/>
datetime    8字节 &#39;1000-01-01 00:00:00.000000&#39; to &#39;9999-12-31 23:59:59.999999<br/>
timestamp   4字节 &#39;1970-01-01 00:00:01.000000&#39; to &#39;2038-01-19 03:14:07.999999&#39;<br/>
相比datetime，timestamp占用更少的空间，以UTC的格式储存自动转换时区。</p>

<p>避免空值<br/>
  MySQL中字段为NULL时依然占用空间，会使索引、索引统计更加复杂。从NULL值更新到非NULL无法做到原地更新，容易发生索引分裂影响性能。尽可能将NULL值用有意义的值代替，也能避免SQL语句里面包含is not null的判断。</p>

<p>text类型优化<br/>
  由于text字段储存大量数据，表容量会很早涨上去，影响其他字段的查询性能。建议抽取出来放在子表里，用业务主键关联。</p>

<p>索引优化<br/>
索引分类<br/>
普通索引：最基本的索引。<br/>
组合索引：多个字段上建立的索引，能够加速复合查询条件的检索。<br/>
唯一索引：与普通索引类似，但索引列的值必须唯一，允许有空值。<br/>
组合唯一索引：列值的组合必须唯一。<br/>
主键索引：特殊的唯一索引，用于唯一标识数据表中的某一条记录，不允许有空值，一般用primary key约束。<br/>
全文索引：用于海量文本的查询，MySQL5.6之后的InnoDB和MyISAM均支持全文索引。由于查询精度以及扩展性不佳，更多的企业选择Elasticsearch。<br/>
索引优化<br/>
分页查询很重要，如果查询数据量超过30%，MYSQL不会使用索引。<br/>
单表索引数不超过5个、单个索引字段数不超过5个。<br/>
字符串可使用前缀索引，前缀长度控制在5-8个字符。<br/>
字段唯一性太低，增加索引没有意义，如：是否删除、性别。<br/>
合理使用覆盖索引，如下所示：<br/>
select login_name, nick_name from member where login_name = ?<br/>
login_name, nick_name两个字段建立组合索引，比login_name简单索引要更快</p>

<p>SQL优化<br/>
分批处理<br/>
  博主小时候看到鱼塘挖开小口子放水，水面有各种漂浮物。浮萍和树叶总能顺利通过出水口，而树枝会挡住其他物体通过，有时还会卡住，需要人工清理。MySQL就是鱼塘，最大并发数和网络带宽就是出水口，用户SQL就是漂浮物。不带分页参数的查询或者影响大量数据的update和delete操作，都是树枝，我们要把它打散分批处理，举例说明：<br/>
业务描述：更新用户所有已过期的优惠券为不可用状态。<br/>
SQL语句：update status=0 FROM <code>coupon</code> WHERE expire_date &lt;= #{currentDate} and status=1;<br/>
如果大量优惠券需要更新为不可用状态，执行这条SQL可能会堵死其他SQL，分批处理伪代码如下：</p>

<p>int pageNo = 1;<br/>
int PAGE_SIZE = 100;<br/>
while(true) {<br/>
    List<Integer> batchIdList = queryList(&#39;select id FROM <code>coupon</code> WHERE expire_date &lt;= #{currentDate} and status = 1 limit #{(pageNo-1) * PAGE_SIZE},#{PAGE_SIZE}&#39;);<br/>
    if (CollectionUtils.isEmpty(batchIdList)) {<br/>
        return;<br/>
    }<br/>
    update(&#39;update status = 0 FROM <code>coupon</code> where status = 1 and id in #{batchIdList}&#39;)<br/>
    pageNo ++;<br/>
}<br/>
操作符&lt;&gt;优化<br/>
  通常&lt;&gt;操作符无法使用索引，举例如下，查询金额不为100元的订单：<br/>
select id from orders where amount != 100;<br/>
如果金额为100的订单极少，这种数据分布严重不均的情况下，有可能使用索引。鉴于这种不确定性，采用union聚合搜索结果，改写方法如下：</p>

<p>(select id from orders where amount &gt; 100)<br/>
 union all<br/>
(select id from orders where amount &lt; 100 and amount &gt; 0)<br/>
OR优化<br/>
  在Innodb引擎下or无法使用组合索引，比如：</p>

<p>select id，product_name from orders where mobile_no = &#39;13421800407&#39; or user_id = 100;<br/>
OR无法命中mobile_no + user_id的组合索引，可采用union，如下所示：</p>

<p>(select id，product_name from orders where mobile_no = &#39;13421800407&#39;)<br/>
 union<br/>
(select id，product_name from orders where user_id = 100);<br/>
此时id和product_name字段都有索引，查询才最高效。</p>

<p>IN优化<br/>
IN适合主表大子表小，EXIST适合主表小子表大。由于查询优化器的不断升级，很多场景这两者性能差不多一样了。<br/>
尝试改为join查询，举例如下：<br/>
select id from orders where user_id in (select id from user where level = &#39;VIP&#39;);<br/>
采用JOIN如下所示：</p>

<p>select o.id from orders o left join user u on o.user_id = u.id where u.level = &#39;VIP&#39;;<br/>
不做列运算<br/>
  通常在查询条件列运算会导致索引失效，如下所示：<br/>
查询当日订单</p>

<p>select id from order where date_format(create_time，&#39;%Y-%m-%d&#39;) = &#39;2019-07-01&#39;;<br/>
date_format函数会导致这个查询无法使用索引，改写后：</p>

<p>select id from order where create_time between &#39;2019-07-01 00:00:00&#39; and &#39;2019-07-01 23:59:59&#39;;<br/>
避免Select all<br/>
  如果不查询表中所有的列，避免使用SELECT *，它会进行全表扫描，不能有效利用索引。</p>

<p>Like优化<br/>
  like用于模糊查询，举个例子（field已建立索引）：</p>

<p>SELECT column FROM table WHERE field like &#39;%keyword%&#39;;<br/>
这个查询未命中索引，换成下面的写法：</p>

<p>SELECT column FROM table WHERE field like &#39;keyword%&#39;;<br/>
去除了前面的%查询将会命中索引，但是产品经理一定要前后模糊匹配呢？全文索引fulltext可以尝试一下，但Elasticsearch才是终极武器。</p>

<p>Join优化<br/>
  join的实现是采用Nested Loop Join算法，就是通过驱动表的结果集作为基础数据，通过该结数据作为过滤条件到下一个表中循环查询数据，然后合并结果。如果有多个join，则将前面的结果集作为循环数据，再次到后一个表中查询数据。</p>

<p>驱动表和被驱动表尽可能增加查询条件，满足ON的条件而少用Where，用小结果集驱动大结果集。<br/>
被驱动表的join字段上加上索引，无法建立索引的时候，设置足够的Join Buffer Size。<br/>
禁止join连接三个以上的表，尝试增加冗余字段。<br/>
Limit优化<br/>
  limit用于分页查询时越往后翻性能越差，解决的原则：缩小扫描范围，如下所示：</p>

<p>select * from orders order by id desc limit 100000,10 <br/>
耗时0.4秒<br/>
select * from orders order by id desc limit 1000000,10<br/>
耗时5.2秒<br/>
先筛选出ID缩小查询范围，写法如下：</p>

<p>select * from orders where id &gt; (select id from orders order by id desc  limit 1000000, 1) order by id desc limit 0,10<br/>
耗时0.5秒<br/>
如果查询条件仅有主键ID，写法如下：</p>

<p>select id from orders where id between 1000000 and 1000010 order by id desc<br/>
耗时0.3秒<br/>
如果以上方案依然很慢呢？只好用游标了，感兴趣的朋友阅读JDBC使用游标实现分页查询的方法</p>

<p>其他数据库<br/>
  作为一名后端开发人员，务必精通作为存储核心的MySQL或SQL Server，也要积极关注NoSQL数据库，他们已经足够成熟并被广泛采用，能解决特定场景下的性能瓶颈。</p>

<p>分类  数据库 特性<br/>
键值型 Memcache    用于内容缓存，大量数据的高访问负载<br/>
键值型 Redis   用于内容缓存，比Memcache支持更多的数据类型，并能持久化数据<br/>
列式存储    HBase   Hadoop体系的核心数据库，海量结构化数据存储，大数据必备。<br/>
文档型 MongoDb 知名文档型数据库，也可以用于缓存<br/>
文档型 CouchDB Apache的开源项目，专注于易用性，支持REST API<br/>
文档型 SequoiaDB   国内知名文档型数据库<br/>
图形  Neo4J   用于社交网络构建关系图谱，推荐系统等</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[遭遇php的in_array低性能]]></title>
    <link href="blog.lilaiqun.com/15706006250325.html"/>
    <updated>2019-10-09T13:57:05+08:00</updated>
    <id>blog.lilaiqun.com/15706006250325.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>转自： <a href="https://www.zendstudio.net/archives/php-in_array-s-low-performance/">https://www.zendstudio.net/archives/php-in_array-s-low-performance/</a></p>
</blockquote>

<pre><code class="language-php">&lt;?php
$y = &quot;1800&quot;;
$x = array();
for($j=0;$j&lt;2000;$j++){
    $x[]= &quot;{$j}&quot;;
}
for($i=0;$i&lt;3000;$i++){
    if(in_array($y,$x)){
            continue;
    }
}
</code></pre>

<p>执行：</p>

<pre><code class="language-text">$ time php test.php

real    0m0.986s
user    0m0.381s
sys 0m0.016s
</code></pre>

<p>对的，我们用的就是字符串型的数字，从缓存拿出来就是这样子的啦！所以这里是特意转成字符串的（如果直接是数字，并不会出现这个问题 ，各位可以自行验证）。可以看出时间耗掉了1秒，才3000次循环,后面的sys用时也注定我们用strace不会拿到什么有效信息。</p>

<pre><code class="language-bash">$ strace -ttt -o xxx php test.php
$ less xxx


</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[zval定义]]></title>
    <link href="blog.lilaiqun.com/15705095538983.html"/>
    <updated>2019-10-08T12:39:13+08:00</updated>
    <id>blog.lilaiqun.com/15705095538983.html</id>
    <content type="html"><![CDATA[
<p>zval可以表示一切PHP中的数据类型, 所以它包含了一个<code>type</code>字段, 表示这个zval存储的是什么类型的值, 常见的可能选项是<code>IS_NULL</code>, <code>IS_LONG</code>, <code>IS_STRING</code>, <code>IS_ARRAY</code>, <code>IS_OBJECT</code>等等.</p>

<pre><code class="language-c"># 文件 zend_types.h
struct _zval_struct {
    zend_value value;   // 8字节
    union u1;           // 4字节
    union u2;           // 4字节
}

# u1
union {
    struct {
        ZEND_ENDIAN_LOHI_4(
            zend_uchar type,    // type就是下面的17种类型
            zend_uchar type_flags,
            zend_uchar const_flags,
            zend_uchar reserved
        )
    } v;
    uint32_t type_info;
} u1;

# u2
union {
    uint32_t next;              // hash collision chain
    uint32_t cache_slot;        //literal cache slot
    uint32_t lineno;            // line number (for ast nodes)
    uint32_t fe_pos;            // foreach position
    uint32_t fe_iter_idx;       // foreach iterator index
    uint32_t access_flags;      // class constant access flags
    uint32_t property_guard;    // single property guard
} u2;

typedef union _zend_value {
    zend_long lval;
    double dval;
    zend_refcounted *counted;
    zend_string *str;
    zend_array *arr;
    zend_object *obj;
    zend_resource *res;
    zend_reference *ref;
    zend_ast_ref *ast;
    zval *zv;
    void *ptr;
    zend_class_entry *ce;
    zend_function *func;
} zend_value;
</code></pre>

<h2 id="toc_0">如何确定变量的类型</h2>

<p>PHP7中的zval的类型做了比较大的调整, 总体来说有如下17种类型:</p>

<pre><code class="language-c">/* regular data types */
#define IS_UNDEF                    0
#define IS_NULL                     1
#define IS_FALSE                    2
#define IS_TRUE                     3
#define IS_LONG                     4
#define IS_DOUBLE                   5
#define IS_STRING                   6
#define IS_ARRAY                    7
#define IS_OBJECT                   8
#define IS_RESOURCE                 9
#define IS_REFERENCE                10
 
/* constant expressions */
#define IS_CONSTANT                 11
#define IS_CONSTANT_AST             12
 
/* fake types */
#define _IS_BOOL                    13
#define IS_CALLABLE                 14
 
/* internal types */
#define IS_INDIRECT                 15
#define IS_PTR                      17
</code></pre>

<h2 id="toc_1">php7中赋值</h2>

<p>1.普通赋值  </p>

<p>在php中，定义一个变量<code>$a=&quot;444&quot;</code>，实际上是生成了一个<code>zval</code>，和一个<code>zend_value</code>,然后<code>zval</code>指向这个<code>zend_value</code>来实现对<code>$a=&quot;444&quot;</code>的定义的，然后通过<code>refcount</code>来统计引用的次数。</p>

<p>refcount表示当前有多少个zval指向同一个zend_value</p>

<p>像<code>bool</code>型还有<code>int</code>，<code>double</code>，<code>null</code>变量，他们的直接通过<code>zval</code>保存，不会公用一个<code>zend_value</code>,所以直接使用深拷贝。<br/>
至于什么是深拷贝，什么是浅拷贝，最直接的区别就是在于<strong>有没有重新生成一个一模一样的zend_value</strong>，详细请参看深拷贝和浅拷贝。</p>

<p>2.引用赋值</p>

<p>php中的引用赋值就是我们常用的引用，例如<code>$a=&amp;$b</code></p>

<p><img src="http://images.lilaiqun.com/15705125876412.jpg" alt=""/></p>

<h2 id="toc_2">查看zval</h2>

<pre><code class="language-php">&lt;?php
$a = 2;
echo $a;
$b = 1.1;
echo $b;
$c = null;
echo $c;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[5分钟商学院]]></title>
    <link href="blog.lilaiqun.com/15704615997009.html"/>
    <updated>2019-10-07T23:19:59+08:00</updated>
    <id>blog.lilaiqun.com/15704615997009.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">概念：信息对称</h2>

<p>所谓信息对称，就是说，在市场条件下，想实现有效的交易，交易双方掌握的信息必须对称，信息如果不对称，掌握信息比较充分的人员，往往会处于比较有利的地位。</p>

<p><strong>运用：场景</strong></p>

<ul>
<li>新创品牌如何获得市场认可？</li>
</ul>

<p>你是一个新创品牌，你做的商品的品质并不 比大牌差，你做的产品卖500块，那些大牌 贴上标签就要卖1000块，这500到1000之间的差价，我们称之为叫品牌溢价。很多人 愿意买大品牌1000块的，是因为宁愿多花 500块也要买一个品质有保障的。<br/>
互联网赋予了你—个可以挑战大品牌的机 会，你只需要选择一个有用户评价的体系， 比如大众点评，比如支付宝，如果你的商品真的很好的话，一个没有品牌的好产品，将有可能迅速战胜一个有品牌的平庸之作。</p>

<p><strong>小结：怎么解决信息不对称的问题？</strong></p>

<p>过去，我们通过品牌连锁经营和担保交易等 等—系列的手段，来解决这个不对称的问 题，但是今天的互联网，给我们提供了—个 全新、高效率地让信息对称的手段，让创造 这些手段的互联网公司，以及善于利用这些 手段的好产品，有机会以小胜大、获得消费 者的认可。信息对称是互联网改变商业世界 的底层逻辑。</p>

<h2 id="toc_1">概念：网络效应</h2>

<p>某种产品对一名用户的价值，取决于使用这 个产品的其他用户的数量，在经济学中，我 们把它称之为：网络效应。用户越多，越有 价值；越有价值，用户越多；不断地积累用 户的黏性。甚至，一旦用户总数突破一个临 界点之后，会最终进入“赢家通吃”的状 态。正如著名的投资人克里斯-迪克森所 说：为工具而来，为网络而留。</p>

<p>微信，使用的人越多，对你就越有价值， 当好友数量达到一定程度时，你们之间就 形成了一张错综复杂的网络。就算有一 天，你打算从微信换到另一个更好用的社 交软件上，也很有可能因为大部分朋友都 在微信上，而不得不回来。</p>

<h2 id="toc_2">概念：边际成本</h2>

<p>边际成本值的是每多生产或者每多卖一件产品，所带来的总成本的增加。边际成本的结构性改变，是互联网经济对传统经济最重要的一个冲击。</p>

<p><strong>案例</strong></p>

<p><strong>苏宁 VS 京东</strong><br/>
苏宁门店只能服务20公里的用户，服务20公里外的用户需要再开家店。边际成本一定不为0，所以单店是否盈利非常重要。<br/>
京东商城前期投入巨大，但互联网能覆盖的用户数，理论上是无上限的，所以边际成本不断递减，最终接近于0.</p>

<p>制造业无法像虚拟产品将边际成本将为0，许多产品的趋势逐步变成：实体产品+虚拟服务。比如电视+媒体库，电话机+话费，用降低实体产品的价格方式，促进虚拟服务达到趋近于0的边际成本。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据库缓存]]></title>
    <link href="blog.lilaiqun.com/15701558070255.html"/>
    <updated>2019-10-04T10:23:27+08:00</updated>
    <id>blog.lilaiqun.com/15701558070255.html</id>
    <content type="html"><![CDATA[
<p>缓存数据是为了很少或不访问数据库服务器，高并发下，最大程度降低对数据服务器压力。</p>

<h2 id="toc_0">启用Mysql查询缓存</h2>

<pre><code class="language-text">query_cache_type
0: 不使用查询缓存
1：始终使用查询缓存
2：按需使用查询缓存

// 不使用
select SQL_NO_CACHE * from my_table;
// 使用
select SQL_CACHE * from my_table;
// 缓存大小
SET GLOBAL query_cache_size = 133333;
// 查看缓存命中次数
SHOW STATUS LIKE &#39;Qcache_hits&#39;

FLUSH QUERY CACHE;
RESET QUERY CACHE;
FLUSH TABLES;
</code></pre>

<table>
<thead>
<tr>
<th></th>
<th>Memcache</th>
<th>Redis</th>
</tr>
</thead>

<tbody>
<tr>
<td></td>
<td></td>
<td>依靠客户端来实现分布式读写</td>
</tr>
<tr>
<td>持久化</td>
<td>不支持</td>
<td>快照、AOF</td>
</tr>
</tbody>
</table>

<h2 id="toc_1">MySQL数据库层的优化</h2>

<p>优化方向： 数据表数据类型优化、索引优化、SQL语句优化、存储引擎的优化、数据表结构设计的优化、数据库服务器架构的优化</p>

<h3 id="toc_2">数据表数据类型优化</h3>

<p>字段使用什么数据类型 <br/>
tinyint smallint bigint<br/>
char varchar</p>

<h2 id="toc_3">索引的优化</h2>

<p>索引创建原则： 不是越多越好，复合索引的前缀原则，全表扫描优化，</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[动态语言的并发处理]]></title>
    <link href="blog.lilaiqun.com/15701061350831.html"/>
    <updated>2019-10-03T20:35:35+08:00</updated>
    <id>blog.lilaiqun.com/15701061350831.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>什么是进程、线程、协程<br/>
什么事多进程、多线程<br/>
同步阻塞模型<br/>
异步非阻塞模型</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">进程的3态模型： 进程在处理器上交替运行，状态在不断发生变化。</h2>

<ul>
<li>运行：进程的数目小于处理器的数目</li>
<li>就绪：进程获取除处理器外一切所需资源。就绪进程可以按多个优先级来划分队列。当进程由于时间片用完进入就绪状态，排入低优先级队列；当进程由I/O操作完成而进入就绪状态时，排入高优先级队列。</li>
<li>阻塞： 等待或睡眠状态，一个进程正在等待某个时间发生（请求IO并等待IO完成）而暂停运行，这是即使把处理器分配给进程也无法运行，故称该进程处于阻塞状态。</li>
</ul>

<h2 id="toc_1">线程的5态模型：</h2>

<ul>
<li>新建态： 刚刚被创建没被提交的状态，等待系统完成创建进程的所有必要信息。</li>
<li>活跃就绪： 进程在主存并可被调度的状态</li>
<li>终止态：进程已结束运行，回收除进程控制块外的其他资源，并让其他进程从进程控制块中收集有关信息</li>
<li>静止就绪：进程被换到辅存时的就绪状态，是不能被直接调度的状态，只有主存中没有活跃就绪态进程，或者是挂起就绪态进程具有更高的优先级，系统将把挂起就绪态进程调回主存并转换为活跃就绪。</li>
<li>活跃阻塞： 进程已在主存，一旦等待时间产生便进入活跃就绪状态。</li>
</ul>

<p>协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器的上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文切换非常快。</p>

<h2 id="toc_2">线程与进程的区别</h2>

<ol>
<li>线程是进程的一个执行单元，进程内至少有一个线程，他们共享进程的地址空间，而进程由自己的独立的地址空间。</li>
<li>进程是资源分配和拥有的单位，同一个进程内的线程共享进程的资源。</li>
<li>线程是处理器调度的基本单位，进程不是</li>
<li>两者均可并发执行</li>
</ol>

<h2 id="toc_3">异步非阻塞</h2>

<p>Reactor有4个核心的操作</p>

<ol>
<li>add添加socket监听到reactor</li>
<li>set修改事件监听，可以设置监听的类型，如可读、可写</li>
<li>del从reactor中移除，不再监听事件</li>
<li>callback 事件发生后对应的处理逻辑，一般在add/set时制定</li>
</ol>

<p>Nginx：多线程Reactor<br/>
Swoole：多线程Reactor + 多进程Worker</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[页面静态化]]></title>
    <link href="blog.lilaiqun.com/15701041292991.html"/>
    <updated>2019-10-03T20:02:09+08:00</updated>
    <id>blog.lilaiqun.com/15701041292991.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">模板引擎Smarty</h2>

<h2 id="toc_1">ob系列函数</h2>

<p>ob_start()<br/>
ob_get_contents()<br/>
ob_clean()<br/>
ob_end_flush()</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浏览器缓存和数据压缩]]></title>
    <link href="blog.lilaiqun.com/15701010542234.html"/>
    <updated>2019-10-03T19:10:54+08:00</updated>
    <id>blog.lilaiqun.com/15701010542234.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">HTTP缓存机制</h2>

<span id="more"></span><!-- more -->

<p>缓存分类，HTTP缓存模型中，如果请求成功会有3中情况：</p>

<ul>
<li>200 from cache： 直接从本地缓存中响应，没有向服务器发送请求</li>
<li>304 Not Modified: 协商缓存，请求头中发送一定的校验数据到服务器，如果服务器数据没有改变浏览器从本地缓存响应，返回304。 快速，发送数据少，只返回一些基本响应头信息，数据量小，不发送实际响应体。</li>
<li>200 OK： 以上两种缓存都失败</li>
</ul>

<h2 id="toc_1">200 from cache 本地缓存相关Header</h2>

<p><strong>Pragma</strong>： HTTP1.0,该字段被设置为no-cache时，会告知浏览器禁用本地缓存，每次都想服务器发送请求。</p>

<p><strong>Expires</strong>： 值形如：Thu，31 Dec格林威治时间，告诉浏览器缓存实现的时刻，标记缓存有效，无需发送请求。</p>

<p><strong>Cache-Control</strong>： </p>

<ul>
<li>no-store： 禁止浏览器缓存响应</li>
<li>no-cache： 不允许直接使用本地缓存，先发起请求和服务器协商</li>
<li>max-age=delta-secondes: 告知浏览器该请求响应本地缓存有效的最长期限，以秒为单位。</li>
</ul>

<p>优先级： Pragma &gt; Cache-Control &gt; Expires</p>

<h2 id="toc_2">304 协商缓存相关Header</h2>

<p><strong>Last-Modified</strong>： 通知浏览器资源的最后修改时间</p>

<p><strong>ETag</strong>： HTTP1.1退出，文件的指纹标识符，如果文件内容修改，指纹会改变</p>

<p><strong>IF-None-Match</strong>： 本地缓存失效，会携带去请求服务端，服务端判断资源是否改变，没有则直接使用本地缓存，返回304</p>

<h2 id="toc_3">适合缓存的内容：</h2>

<p>图片、css</p>

<h2 id="toc_4">使用协商缓存</h2>

<p>HTML文件<br/>
js、css文件的加载可以加入文件签名拒绝缓存<br/>
index.css?签名<br/>
index.签名.js</p>

<h2 id="toc_5">Nginx配置缓存策略</h2>

<p>本地缓存配置<br/>
add_header指令： 添加状态码2XX和3XX的响应头信息<br/>
add_header name value [always];<br/>
可以设置Pragma、Expires、Cache-Control 可以继承</p>

<p>gzip 压缩</p>

<pre><code class="language-text">gzip on
gzip_buffers 32 4k|16 8K #内存中缓冲几块 大小
gzip_comp_level [1-9] #推荐6 压缩级别（级别越高，浪费CPU计算资源）
gzip_min_length 200 #开始压缩的最小长度
gzip_http_version 1.0|1.1
gzip_proxied  #设置请求者代理服务器，该如何缓存内容
gzip_types text/plain applicatin/xml #对那些类型的文件压缩
gzip_vary on|off  #是否传输gzip压缩标识


</code></pre>

<h2 id="toc_6">自动化压缩</h2>

<p>Grunt</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[减少HTTP请求]]></title>
    <link href="blog.lilaiqun.com/15700996704794.html"/>
    <updated>2019-10-03T18:47:50+08:00</updated>
    <id>blog.lilaiqun.com/15700996704794.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">为什么要减少？</h2>

<p>80%的时间花在html文档所引用的组件（图片、css、script等）进行的HTTP请求上。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">HTTP链接产生的开销</h2>

<p>域名解析、TCP连接、发送请求、等待、下载资源、解析时间</p>

<p><strong>图片地图</strong></p>

<pre><code class="language-text">&lt;img usemap=&quot;#map1&quot;&gt;
&lt;map name=&quot;map1&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;HOME&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;GIFT&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;Cart&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;HELP&quot;&gt;

&lt;/map&gt;
</code></pre>

<p><strong>css精灵</strong></p>

<p>background-position属性</p>

<p><strong>合并js脚本和样式表</strong></p>

<p><strong>使用Base64编码减少页面请求数</strong></p>

<p>通过Base64编码方式将图片直接嵌入网页中</p>

<pre><code class="language-text">&lt;img src=&quot;data:image/gif;base64,/...&quot;&gt;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web资源防盗链]]></title>
    <link href="blog.lilaiqun.com/15700981798015.html"/>
    <updated>2019-10-03T18:22:59+08:00</updated>
    <id>blog.lilaiqun.com/15700981798015.html</id>
    <content type="html"><![CDATA[
<p>常见的就是小站盗用大站的图片、音乐、视频、软件的资源<br/>
通过盗链的方法可以减轻自己服务器的负担，真实空间来自别人的服务器</p>

<p>工作原理：<br/>
通过Referer或者签名计算（规定的加密数字）</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1.通过Nginx配置</h2>

<p>Nginx模块 ngx_http_referer_module 用来阻挡来源非法的域名请求<br/>
Nginx指令 valid_referers, 全局变量$invalid_referer </p>

<pre><code class="language-text">valid_referers none | blocked | server_names | string;

// 参数详情：
none: &quot;Referer&quot; 来源头部为空的情况
blocked: &quot;Referer&quot; 来源头部不为空，但是里面的值被代理或防火墙删除了，这些值都不以http:// https://开头
server_names:  &quot;Referer&quot; 来源头部包含当前的server_names
</code></pre>

<p>简单示例：</p>

<pre><code class="language-text">location ~ .*\.(gif|jpg|png|flv|swf|rar|zip)$
{
    valid_referers none blocked lilaiqun.com *.lilaiqun.com;
    if ($invalid_referer) 
    {
        #return 403;
        rewite ^/ http://www.lilaiqun.com/403.jpg;
    }
}
</code></pre>

<h2 id="toc_1">2.使用加密签名</h2>

<p>使用第三方模块HttpAccessKeyModule实现Nginx防盗链<br/>
accesskey on|off 模块开关<br/>
accesskey_hashmethod md5|sha-1 签名加密方式<br/>
accesskey_arg GET参数名称<br/>
accesskey_signature 加密规则</p>

<pre><code class="language-text">location ~ .*\.(gif|jpg|png|flv|swf|rar|zip)$
{
    accesskey on;
    accesskey_hashmethod md5;
    accesskey_arg &quot;key&quot;;
    accesskey_signature &quot;mypass$remote_addr&quot;;
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高并发结构]]></title>
    <link href="blog.lilaiqun.com/15700944894509.html"/>
    <updated>2019-10-03T17:21:29+08:00</updated>
    <id>blog.lilaiqun.com/15700944894509.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>并发：相同时间点，有多少个访问同时到来。一个系统日PV在千万以上，有可能是一个高并发系统<br/>
QPS：每秒钟请求或者查询的数量，每秒响应的请求量<br/>
吞吐量：单位时间内处理的请求数量</p>
</blockquote>

<h2 id="toc_0">高并发的问题，我们具体该关心什么？</h2>

<p>（总PV数 * 0.8）/ (6*3600 * 0.2) = 峰值每秒请求数（QPS）<br/>
80%的访问量集中在20%的时间</p>

<h2 id="toc_1">高并发解决方案案例</h2>

<p>流量优化： <a href="15700981798015.html">Web资源防盗链</a><br/>
前端优化： <a href="15700996704794.html">减少HTTP请求</a>、添加异步请求、<a href="15701010542234.html">浏览器缓存和数据压缩</a>、CDN加速、建立图片服务器<br/>
服务端优化： <a href="15701041292991.html">页面静态化</a>、并发处理（多线程异步、队列异步处理）<br/>
数据库优化： <a href="15701558070255.html">数据库缓存</a>、分库分表、分区操作、读写分离<br/>
Web服务器优化： 负载均衡</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何解决消息队列中的延迟]]></title>
    <link href="blog.lilaiqun.com/15700896906629.html"/>
    <updated>2019-10-03T16:01:30+08:00</updated>
    <id>blog.lilaiqun.com/15700896906629.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问： 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">面试官心里分析</h2>

<p>你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了，或者消费的极其极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如rabbitmq设置了消息过期时间后就没了怎么办？</p>

<p>所以就这事儿，其实线上挺常见的，一般不出，一出就是大case，一般常见于，举个例子，消费端每次消费之后要写mysql，结果mysql挂了，消费端hang那儿了，不动了。或者是消费端出了个什么叉子，导致消费速度极其慢。</p>

<h2 id="toc_1">面试题分析</h2>

<p>关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在mq里积压，现在事故了，慌了</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息的顺序性？]]></title>
    <link href="blog.lilaiqun.com/15700882317067.html"/>
    <updated>2019-10-03T15:37:11+08:00</updated>
    <id>blog.lilaiqun.com/15700882317067.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问：如何保证消息的顺序性</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">面试题剖析：</h2>

<p>我举个例子，我们以前做过一个mysql binlog同步的系统，压力还是非常大的，日同步数据要达到上亿。mysql -&gt; mysql，常见的一点在于说大数据team，就需要同步一个mysql库过来，对公司的业务系统的数据做各种复杂的操作。</p>

<p>你在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。</p>

<p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p>

<p>先看看顺序会错乱的俩场景</p>

<p>（1）rabbitmq：一个queue，多个consumer，这不明显乱了<br/>
（2）kafka：一个topic，一个partition，一个consumer，<strong>内部多线程</strong>，这不也明显乱了</p>

<p><img src="http://images.lilaiqun.com/15700893668371.jpg" alt="kafka消息错乱"/></p>

<p>那如何保证消息的顺序性呢？简单简单</p>

<p>（1）rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理</p>

<p>（2）kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可</p>

<p><img src="http://images.lilaiqun.com/15700892292208.jpg" alt="kafka消息错乱解决方案"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息队列的可靠性（消息不丢）]]></title>
    <link href="blog.lilaiqun.com/15700740718336.html"/>
    <updated>2019-10-03T11:41:11+08:00</updated>
    <id>blog.lilaiqun.com/15700740718336.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问： 如何保证消息的可靠性传输（如何处理消息丢失的问题）？</p>
</blockquote>

<span id="more"></span><!-- more -->

<p>如果说你这个是用mq来传递非常核心的消息，比如说计费，扣费的一些消息，因为我以前设计和研发过一个公司非常核心的广告平台，计费系统，计费系统是很重的一个业务，操作是很耗时的。所以说广告系统整体的架构里面，实际上是将计费做成异步化的，然后中间就是加了一个MQ。</p>

<p>我们当时为了确保说这个MQ传递过程中绝对不会把计费消息给弄丢，花了很多的精力。广告主投放了一个广告，明明说好了，用户点击一次扣费1块钱。结果要是用户动不动点击了一次，扣费的时候搞的消息丢了，我们公司就会不断的少几块钱，几块钱，积少成多，这个就对公司是一个很大的损失。</p>

<h2 id="toc_0">面试题剖析</h2>

<p>这个丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了。咱们从rabbitmq和kafka分别来分析一下吧</p>

<p>rabbitmq这种mq，一般来说都是承载公司的核心业务的，数据是绝对不能弄丢的</p>

<h3 id="toc_1">1.Rabbitmq</h3>

<p><img src="http://images.lilaiqun.com/15700881424752.jpg" alt=""/></p>

<p>1）生产者弄丢了数据</p>

<p>生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。</p>

<p>此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。</p>

<p>所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p>

<p>事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。</p>

<p>所以一般在生产者这块避免数据丢失，都是用confirm机制的。</p>

<p>2）rabbitmq弄丢了数据</p>

<p>就是rabbitmq自己弄丢了数据，这个你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。</p>

<p>设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。</p>

<p>而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。</p>

<p>哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。</p>

<p>3）消费端弄丢了数据</p>

<p>rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。</p>

<p>这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。</p>

<h3 id="toc_2">2.kafka</h3>

<p><img src="http://images.lilaiqun.com/15700881304080.jpg" alt=""/></p>

<p>1）消费端弄丢了数据</p>

<p>唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p>

<p>这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p>

<p>生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。</p>

<p>然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了</p>

<p>2）kafka弄丢了数据</p>

<p>这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。</p>

<p>生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了</p>

<p>所以此时一般是要求起码设置如下4个参数：</p>

<p>给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本</p>

<p>在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧</p>

<p>在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了</p>

<p>在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了</p>

<p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失</p>

<p>3）生产者会不会弄丢数据</p>

<p>如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息不被重复消费（消费时的幂等性）]]></title>
    <link href="blog.lilaiqun.com/15700210659906.html"/>
    <updated>2019-10-02T20:57:45+08:00</updated>
    <id>blog.lilaiqun.com/15700210659906.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="http://images.lilaiqun.com/%E5%9B%BE%E7%89%87.png" alt="Kafka图示"/><br/>
<img src="http://images.lilaiqun.com/15700216386343.jpg" alt=""/></p>

<p>回答这个问题，首先你别听到重复消息这个事儿，就一无所知吧，你先大概说一说可能会有哪些重复消费的问题。</p>

<p>首先就是比如rabbitmq、rocketmq、kafka，都有可能会出现消费重复消费的问题，正常。因为这问题通常不是mq自己保证的，是给你保证的。然后我们挑一个kafka来举个例子，说说怎么重复消费吧。</p>

<p>kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。</p>

<p>但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。</p>

<p><strong>其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。</strong></p>

<p>给你举个例子吧。假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，不就保留了一条数据？</p>

<p>一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性</p>

<p>幂等性，我通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。</p>

<p>那所以第二个问题来了，怎么保证消息队列消费的幂等性？</p>

<p>其实还是得结合业务来思考，我这里给几个思路：</p>

<p>（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧</p>

<p>（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性</p>

<p>（3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</p>

<p>还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据</p>

<p>如何保证MQ的消费是幂等性的，需要结合具体的业务来看</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息队列的高可用啊？]]></title>
    <link href="blog.lilaiqun.com/15700185588826.html"/>
    <updated>2019-10-02T20:15:58+08:00</updated>
    <id>blog.lilaiqun.com/15700185588826.html</id>
    <content type="html"><![CDATA[
<p>问题：</p>

<pre><code class="language-text">MQ的缺点：系统可用性降低。接下来围绕MQ的缺点怎么解决。

MQ的高可用性怎么保证？ 
</code></pre>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1. RabbitMQ的高可用</h2>

<p>RabbitMQ比较有代表性，因为是基于主从架构</p>

<p>3种模式：<strong>单机模式，普通集群模式，镜像集群模式</strong></p>

<p>1）单机模式</p>

<p>就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式</p>

<p>2）普通集群模式</p>

<p><img src="http://images.lilaiqun.com/15700196661169.jpg" alt=""/></p>

<p>意思就是在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。</p>

<p>这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。</p>

<p>而且如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。</p>

<p>所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作。</p>

<p>3）镜像集群模式</p>

<p><img src="http://images.lilaiqun.com/15700197102596.jpg" alt=""/></p>

<p>这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。</p>

<p>这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue</p>

<p>那么怎么开启这个镜像集群模式呢？我这里简单说一下，避免面试人家问你你不知道，其实很简单rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p>

<h2 id="toc_1">2. kakfa</h2>

<p><img src="http://images.lilaiqun.com/15700200076415.jpg" alt=""/></p>

<p>kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。</p>

<p>这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。</p>

<p>实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。</p>

<p>kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。</p>

<p>kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。</p>

<p>这么搞，就有所谓的高可用性了，因为如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。</p>

<p>写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）</p>

<p>消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。</p>

<p>实际上这块机制，讲深了，是可以非常之深入的，但是我还是回到我们这个课程的主题和定位，聚焦面试，至少你听到这里大致明白了kafka是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要遇上面试官确实是kafka高手，深挖了问，那你只能说不好意思，太深入的你没研究过。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[消息队列技术选型]]></title>
    <link href="blog.lilaiqun.com/15700030762829.html"/>
    <updated>2019-10-02T15:57:56+08:00</updated>
    <id>blog.lilaiqun.com/15700030762829.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1.为何使用消息队列</h2>

<p><code>解耦、异步、消峰</code></p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">2.缺点</h2>

<ol>
<li>可用性降低，系统太依赖消息队列<br/></li>
<li>增加系统复杂性，发送多次消息<br/></li>
<li>一致性问题，消息发送顺序错误，导致结果错误<br/></li>
</ol>

<table>
<thead>
<tr>
<th></th>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>RocketMQ</th>
<th>Kafka</th>
</tr>
</thead>

<tbody>
<tr>
<td>吞吐量</td>
<td>万级</td>
<td>万级</td>
<td>10万级</td>
<td>10万级</td>
</tr>
<tr>
<td>topic数量对吞吐量影响</td>
<td>万级</td>
<td>万级</td>
<td>topic可以达到几千级别，吞吐量会小幅度下降</td>
<td>topic从几十到几百个的时候，吞吐量会大幅度下降。 所以同等机器下，kafka尽量保证topic数量不要过多</td>
</tr>
<tr>
<td>时效性</td>
<td>ms级</td>
<td>微妙级，延迟最低</td>
<td>ms级</td>
<td>ms以内</td>
</tr>
<tr>
<td>可用性</td>
<td>搞，基于主从架构实现高可用</td>
<td>高，基于主从架构</td>
<td>非常高，分布式</td>
<td>非常高，分布式，一个数据多个副本，不会丢失数据</td>
</tr>
<tr>
<td>消息可靠性</td>
<td>低概率丢失</td>
<td></td>
<td>通过参数优化配置，0丢失</td>
<td>通过参数优化配置，0丢失</td>
</tr>
<tr>
<td>功能支持</td>
<td>MQ功能极其完备</td>
<td>自带后台适合小型公司，社区活跃，基于erlang开发，开发能力强，延迟很低</td>
<td>MQ功能比较完善，还是分布式的，扩展性好</td>
<td>支持简单MQ功能，在大数据领域的实时计算以及日志采集被大规模使用</td>
</tr>
<tr>
<td>优劣势</td>
<td>非常成熟，功能强大</td>
<td>erlang开发，性能好，延迟低</td>
<td>接口简单</td>
<td>吞吐量搞，大数据领域的日志采集</td>
</tr>
</tbody>
</table>

<h2 id="toc_2">RabbitMq</h2>

<h2 id="toc_3">MQ</h2>

<h2 id="toc_4">Redis</h2>

<h2 id="toc_5">Kafka</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[目录接口]]></title>
    <link href="blog.lilaiqun.com/15700028122851.html"/>
    <updated>2019-10-02T15:53:32+08:00</updated>
    <id>blog.lilaiqun.com/15700028122851.html</id>
    <content type="html"><![CDATA[
<p>编译与执行<br/>
词法、语法分析基本原理<br/>
抽象语法书<br/>
Zend虚拟机</p>

<h2 id="toc_0">基本语法与扩展编写</h2>

<p><a href="#">各类基础语法的实现</a><br/>
<a href="#">手把手编写一个PHP扩展</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[面试官：给我讲一下分库分表方案]]></title>
    <link href="blog.lilaiqun.com/15647135075311.html"/>
    <updated>2019-08-02T10:38:27+08:00</updated>
    <id>blog.lilaiqun.com/15647135075311.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<blockquote>
<p>作者：尜尜人物<br/>
  链接：<a href="https://www.cnblogs.com/littlecharacter/p/9342129.html">https://www.cnblogs.com/littlecharacter/p/9342129.html</a></p>
</blockquote>

<ul>
<li>
<a href="#toc_0">一、数据库瓶颈</a>
<ul>
<li>
<a href="#toc_1">1、IO瓶颈</a>
</li>
<li>
<a href="#toc_2">2、CPU瓶颈</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">二、分库分表</a>
<ul>
<li>
<a href="#toc_4">1、水平分库</a>
</li>
<li>
<a href="#toc_5">2、水平分表</a>
</li>
<li>
<a href="#toc_6">3、垂直分库</a>
</li>
<li>
<a href="#toc_7">4、垂直分表</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">三、分库分表工具</a>
</li>
<li>
<a href="#toc_9">四、分库分表步骤</a>
</li>
<li>
<a href="#toc_10">五、分库分表问题</a>
<ul>
<li>
<a href="#toc_11">1. 非partition key的查询问题（水平分库分表，拆分策略为常用的hash法）</a>
</li>
<li>
<a href="#toc_12">2、非partition key跨库跨表分页查询问题（水平分库分表，拆分策略为常用的hash法）</a>
</li>
<li>
<a href="#toc_13">3、扩容问题（水平分库分表，拆分策略为常用的hash法）</a>
</li>
</ul>
</li>
<li>
<a href="#toc_14">六、分库分表总结</a>
</li>
<li>
<a href="#toc_15">七、分库分表示例</a>
</li>
</ul>


<h2 id="toc_0">一、数据库瓶颈</h2>

<p>不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。接下来就可以想象了吧（并发量、吞吐量、崩溃）。</p>

<h3 id="toc_1">1、IO瓶颈</h3>

<p>第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -&gt; 分库和垂直分表。<br/>
第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -&gt; 分库。</p>

<h3 id="toc_2">2、CPU瓶颈</h3>

<p>第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作 -&gt; SQL优化，建立合适的索引，在业务Service层进行业务计算。<br/>
第二种：单表数据量太大，查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈 -&gt; 水平分表。</p>

<h2 id="toc_3">二、分库分表</h2>

<h3 id="toc_4">1、水平分库</h3>

<p><img src="http://images.lilaiqun.com/15647137481060.jpg" alt=""/></p>

<ol>
<li><p>概念：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。</p></li>
<li><p>结果：</p></li>
<li><p>每个库的结构都一样；</p></li>
<li><p>每个库的数据都不一样，没有交集；</p></li>
<li><p>所有库的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。</p></li>
<li><p>分析：库多了，io和cpu的压力自然可以成倍缓解。</p></li>
</ol>

<h3 id="toc_5">2、水平分表</h3>

<p><img src="http://images.lilaiqun.com/15647137986218.jpg" alt=""/></p>

<ol>
<li><p>概念：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。</p></li>
<li><p>结果：<br/>
每个表的结构都一样；<br/>
每个表的数据都不一样，没有交集；<br/>
所有表的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。</p></li>
<li><p>分析：表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。</p></li>
</ol>

<h3 id="toc_6">3、垂直分库</h3>

<p><img src="http://images.lilaiqun.com/15647138213351.jpg" alt=""/></p>

<ol>
<li>概念：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。</li>
<li>结果：</li>
<li>每个库的结构都不一样；</li>
<li>每个库的数据也不一样，没有交集；</li>
<li><p>所有库的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。</p></li>
<li><p>分析：到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。</p></li>
</ol>

<h3 id="toc_7">4、垂直分表</h3>

<p><img src="http://images.lilaiqun.com/15647138576584.jpg" alt=""/></p>

<ol>
<li><p>概念：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。</p></li>
<li><p>结果：</p></li>
<li><p>每个表的结构都不一样；</p></li>
<li><p>每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；</p></li>
<li><p>所有表的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。</p></li>
<li><p>分析：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。</p></li>
</ol>

<h2 id="toc_8">三、分库分表工具</h2>

<ol>
<li>sharding-sphere：jar，前身是sharding-jdbc；</li>
<li>TDDL：jar，Taobao Distribute Data Layer；</li>
<li>Mycat：中间件。</li>
</ol>

<p>注：工具的利弊，请自行调研，官网和社区优先。</p>

<h2 id="toc_9">四、分库分表步骤</h2>

<p>根据容量（当前容量和增长量）评估分库或分表个数 -&gt; 选key（均匀）-&gt; 分表规则（hash或range等）-&gt; 执行（一般双写）-&gt; 扩容问题（尽量减少数据的移动）。</p>

<h2 id="toc_10">五、分库分表问题</h2>

<h3 id="toc_11">1. 非partition key的查询问题（水平分库分表，拆分策略为常用的hash法）</h3>

<p>除了partition key只有一个非partition key作为条件查询</p>

<p><strong>映射法</strong><br/>
<img src="http://images.lilaiqun.com/15647140231654.jpg" alt=""/></p>

<p><strong>基因法</strong><br/>
<img src="http://images.lilaiqun.com/15647140318991.jpg" alt=""/></p>

<p>注：写入时，基因法生成user_id，如图。关于xbit基因，例如要分8张表，23=8，故x取3，即3bit基因。根据user_id查询时可直接取模路由到对应的分库或分表。根据user_name查询时，先通过user_name_code生成函数生成user_name_code再对其取模路由到对应的分库或分表。id生成常用<strong>snowflake算法</strong>。</p>

<ol>
<li>端上除了partition key不止一个非partition key作为条件查询</li>
</ol>

<p><strong>映射法</strong><br/>
<img src="http://images.lilaiqun.com/15647140607030.jpg" alt=""/></p>

<p><strong>冗余法</strong><br/>
<img src="http://images.lilaiqun.com/15647140694844.jpg" alt=""/></p>

<p>注：按照order_id或buyer_id查询时路由到db_o_buyer库中，按照seller_id查询时路由到db_o_seller库中。感觉有点本末倒置！有其他好的办法吗？改变技术栈呢？</p>

<p>3、后台除了partition key还有各种非partition key组合条件查询</p>

<p><strong>NoSQL法</strong><br/>
<img src="http://images.lilaiqun.com/15647150946637.jpg" alt=""/></p>

<p><strong>冗余法</strong><br/>
<img src="http://images.lilaiqun.com/15647151004264.jpg" alt=""/></p>

<h3 id="toc_12">2、非partition key跨库跨表分页查询问题（水平分库分表，拆分策略为常用的hash法）</h3>

<p>注：用NoSQL法解决（ES等）。</p>

<h3 id="toc_13">3、扩容问题（水平分库分表，拆分策略为常用的hash法）</h3>

<p>1、水平扩容库（升级从库法<br/>
<img src="http://images.lilaiqun.com/15647151413436.jpg" alt=""/></p>

<p>注：扩容是成倍的。</p>

<p>2、水平扩容表（双写迁移法）<br/>
<img src="http://images.lilaiqun.com/15647151512396.jpg" alt=""/></p>

<p>第一步：（同步双写）应用配置双写，部署；<br/>
第二步：（同步双写）将老库中的老数据复制到新库中；<br/>
第三步：（同步双写）以老库为准校对新库中的老数据；<br/>
第四步：（同步双写）应用去掉双写，部署；</p>

<p>注：双写是通用方案。</p>

<h2 id="toc_14">六、分库分表总结</h2>

<p>分库分表，首先得知道瓶颈在哪里，然后才能合理地拆分（分库还是分表？水平还是垂直？分几个？）。且不可为了分库分表而拆分。</p>

<p>1、选key很重要，既要考虑到拆分均匀，也要考虑到非partition key的查询。<br/>
2、只要能满足需求，拆分规则越简单越好。</p>

<h2 id="toc_15">七、分库分表示例</h2>

<p>示例GitHub地址：<a href="https://github.com/littlecharacter4s/study-sharding">https://github.com/littlecharacter4s/study-sharding</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Excel制作二维码]]></title>
    <link href="blog.lilaiqun.com/15644556452076.html"/>
    <updated>2019-07-30T11:00:45+08:00</updated>
    <id>blog.lilaiqun.com/15644556452076.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="http://images.lilaiqun.com/Excel%E5%88%B6%E4%BD%9C%E4%BA%8C%E7%BB%B4%E7%A0%81.png" alt="Excel制作二维码"/></p>

]]></content>
  </entry>
  
</feed>
