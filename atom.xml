<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[lilaiqun]]></title>
  <link href="blog.lilaiqun.com/atom.xml" rel="self"/>
  <link href="blog.lilaiqun.com/"/>
  <updated>2019-10-03T20:02:07+08:00</updated>
  <id>blog.lilaiqun.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[数据库缓存]]></title>
    <link href="blog.lilaiqun.com/15701558070255.html"/>
    <updated>2019-10-04T10:23:27+08:00</updated>
    <id>blog.lilaiqun.com/15701558070255.html</id>
    <content type="html"><![CDATA[
<p>缓存数据是为了很少或不访问数据库服务器，高并发下，最大程度降低对数据服务器压力。</p>

<h2 id="toc_0">启用Mysql查询缓存</h2>

<pre><code class="language-text">query_cache_type
0: 不使用查询缓存
1：始终使用查询缓存
2：按需使用查询缓存

// 不使用
select SQL_NO_CACHE * from my_table;
// 使用
select SQL_CACHE * from my_table;
// 缓存大小
SET GLOBAL query_cache_size = 133333;
// 查看缓存命中次数
SHOW STATUS LIKE &#39;Qcache_hits&#39;

FLUSH QUERY CACHE;
RESET QUERY CACHE;
FLUSH TABLES;
</code></pre>

<table>
<thead>
<tr>
<th></th>
<th>Memcache</th>
<th>Redis</th>
</tr>
</thead>

<tbody>
<tr>
<td></td>
<td></td>
<td>依靠客户端来实现分布式读写</td>
</tr>
<tr>
<td>持久化</td>
<td>不支持</td>
<td>快照、AOF</td>
</tr>
</tbody>
</table>

<h2 id="toc_1">MySQL数据库层的优化</h2>

<p>优化方向： 数据表数据类型优化、索引优化、SQL语句优化、存储引擎的优化、数据表结构设计的优化、数据库服务器架构的优化</p>

<h3 id="toc_2">数据表数据类型优化</h3>

<p>字段使用什么数据类型 <br/>
tinyint smallint bigint<br/>
char varchar</p>

<h2 id="toc_3">索引的优化</h2>

<p>索引创建原则： 不是越多越好，复合索引的前缀原则，全表扫描优化，</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[动态语言的并发处理]]></title>
    <link href="blog.lilaiqun.com/15701061350831.html"/>
    <updated>2019-10-03T20:35:35+08:00</updated>
    <id>blog.lilaiqun.com/15701061350831.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>什么是进程、线程、协程<br/>
什么事多进程、多线程<br/>
同步阻塞模型<br/>
异步非阻塞模型</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">进程的3态模型： 进程在处理器上交替运行，状态在不断发生变化。</h2>

<ul>
<li>运行：进程的数目小于处理器的数目</li>
<li>就绪：进程获取除处理器外一切所需资源。就绪进程可以按多个优先级来划分队列。当进程由于时间片用完进入就绪状态，排入低优先级队列；当进程由I/O操作完成而进入就绪状态时，排入高优先级队列。</li>
<li>阻塞： 等待或睡眠状态，一个进程正在等待某个时间发生（请求IO并等待IO完成）而暂停运行，这是即使把处理器分配给进程也无法运行，故称该进程处于阻塞状态。</li>
</ul>

<h2 id="toc_1">线程的5态模型：</h2>

<ul>
<li>新建态： 刚刚被创建没被提交的状态，等待系统完成创建进程的所有必要信息。</li>
<li>活跃就绪： 进程在主存并可被调度的状态</li>
<li>终止态：进程已结束运行，回收除进程控制块外的其他资源，并让其他进程从进程控制块中收集有关信息</li>
<li>静止就绪：进程被换到辅存时的就绪状态，是不能被直接调度的状态，只有主存中没有活跃就绪态进程，或者是挂起就绪态进程具有更高的优先级，系统将把挂起就绪态进程调回主存并转换为活跃就绪。</li>
<li>活跃阻塞： 进程已在主存，一旦等待时间产生便进入活跃就绪状态。</li>
</ul>

<p>协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器的上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文切换非常快。</p>

<h2 id="toc_2">线程与进程的区别</h2>

<ol>
<li>线程是进程的一个执行单元，进程内至少有一个线程，他们共享进程的地址空间，而进程由自己的独立的地址空间。</li>
<li>进程是资源分配和拥有的单位，同一个进程内的线程共享进程的资源。</li>
<li>线程是处理器调度的基本单位，进程不是</li>
<li>两者均可并发执行</li>
</ol>

<h2 id="toc_3">异步非阻塞</h2>

<p>Reactor有4个核心的操作</p>

<ol>
<li>add添加socket监听到reactor</li>
<li>set修改事件监听，可以设置监听的类型，如可读、可写</li>
<li>del从reactor中移除，不再监听事件</li>
<li>callback 事件发生后对应的处理逻辑，一般在add/set时制定</li>
</ol>

<p>Nginx：多线程Reactor<br/>
Swoole：多线程Reactor + 多进程Worker</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[页面静态化]]></title>
    <link href="blog.lilaiqun.com/15701041292991.html"/>
    <updated>2019-10-03T20:02:09+08:00</updated>
    <id>blog.lilaiqun.com/15701041292991.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">模板引擎Smarty</h2>

<h2 id="toc_1">ob系列函数</h2>

<p>ob_start()<br/>
ob_get_contents()<br/>
ob_clean()<br/>
ob_end_flush()</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浏览器缓存和数据压缩]]></title>
    <link href="blog.lilaiqun.com/15701010542234.html"/>
    <updated>2019-10-03T19:10:54+08:00</updated>
    <id>blog.lilaiqun.com/15701010542234.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">HTTP缓存机制</h2>

<span id="more"></span><!-- more -->

<p>缓存分类，HTTP缓存模型中，如果请求成功会有3中情况：</p>

<ul>
<li>200 from cache： 直接从本地缓存中响应，没有向服务器发送请求</li>
<li>304 Not Modified: 协商缓存，请求头中发送一定的校验数据到服务器，如果服务器数据没有改变浏览器从本地缓存响应，返回304。 快速，发送数据少，只返回一些基本响应头信息，数据量小，不发送实际响应体。</li>
<li>200 OK： 以上两种缓存都失败</li>
</ul>

<h2 id="toc_1">200 from cache 本地缓存相关Header</h2>

<p><strong>Pragma</strong>： HTTP1.0,该字段被设置为no-cache时，会告知浏览器禁用本地缓存，每次都想服务器发送请求。</p>

<p><strong>Expires</strong>： 值形如：Thu，31 Dec格林威治时间，告诉浏览器缓存实现的时刻，标记缓存有效，无需发送请求。</p>

<p><strong>Cache-Control</strong>： </p>

<ul>
<li>no-store： 禁止浏览器缓存响应</li>
<li>no-cache： 不允许直接使用本地缓存，先发起请求和服务器协商</li>
<li>max-age=delta-secondes: 告知浏览器该请求响应本地缓存有效的最长期限，以秒为单位。</li>
</ul>

<p>优先级： Pragma &gt; Cache-Control &gt; Expires</p>

<h2 id="toc_2">304 协商缓存相关Header</h2>

<p><strong>Last-Modified</strong>： 通知浏览器资源的最后修改时间</p>

<p><strong>ETag</strong>： HTTP1.1退出，文件的指纹标识符，如果文件内容修改，指纹会改变</p>

<p><strong>IF-None-Match</strong>： 本地缓存失效，会携带去请求服务端，服务端判断资源是否改变，没有则直接使用本地缓存，返回304</p>

<h2 id="toc_3">适合缓存的内容：</h2>

<p>图片、css</p>

<h2 id="toc_4">使用协商缓存</h2>

<p>HTML文件<br/>
js、css文件的加载可以加入文件签名拒绝缓存<br/>
index.css?签名<br/>
index.签名.js</p>

<h2 id="toc_5">Nginx配置缓存策略</h2>

<p>本地缓存配置<br/>
add_header指令： 添加状态码2XX和3XX的响应头信息<br/>
add_header name value [always];<br/>
可以设置Pragma、Expires、Cache-Control 可以继承</p>

<p>gzip 压缩</p>

<pre><code class="language-text">gzip on
gzip_buffers 32 4k|16 8K #内存中缓冲几块 大小
gzip_comp_level [1-9] #推荐6 压缩级别（级别越高，浪费CPU计算资源）
gzip_min_length 200 #开始压缩的最小长度
gzip_http_version 1.0|1.1
gzip_proxied  #设置请求者代理服务器，该如何缓存内容
gzip_types text/plain applicatin/xml #对那些类型的文件压缩
gzip_vary on|off  #是否传输gzip压缩标识


</code></pre>

<h2 id="toc_6">自动化压缩</h2>

<p>Grunt</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[减少HTTP请求]]></title>
    <link href="blog.lilaiqun.com/15700996704794.html"/>
    <updated>2019-10-03T18:47:50+08:00</updated>
    <id>blog.lilaiqun.com/15700996704794.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">为什么要减少？</h2>

<p>80%的时间花在html文档所引用的组件（图片、css、script等）进行的HTTP请求上。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">HTTP链接产生的开销</h2>

<p>域名解析、TCP连接、发送请求、等待、下载资源、解析时间</p>

<p><strong>图片地图</strong></p>

<pre><code class="language-text">&lt;img usemap=&quot;#map1&quot;&gt;
&lt;map name=&quot;map1&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;HOME&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;GIFT&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;Cart&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;HELP&quot;&gt;

&lt;/map&gt;
</code></pre>

<p><strong>css精灵</strong></p>

<p>background-position属性</p>

<p><strong>合并js脚本和样式表</strong></p>

<p><strong>使用Base64编码减少页面请求数</strong></p>

<p>通过Base64编码方式将图片直接嵌入网页中</p>

<pre><code class="language-text">&lt;img src=&quot;data:image/gif;base64,/...&quot;&gt;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web资源防盗链]]></title>
    <link href="blog.lilaiqun.com/15700981798015.html"/>
    <updated>2019-10-03T18:22:59+08:00</updated>
    <id>blog.lilaiqun.com/15700981798015.html</id>
    <content type="html"><![CDATA[
<p>常见的就是小站盗用大站的图片、音乐、视频、软件的资源<br/>
通过盗链的方法可以减轻自己服务器的负担，真实空间来自别人的服务器</p>

<p>工作原理：<br/>
通过Referer或者签名计算（规定的加密数字）</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1.通过Nginx配置</h2>

<p>Nginx模块 ngx_http_referer_module 用来阻挡来源非法的域名请求<br/>
Nginx指令 valid_referers, 全局变量$invalid_referer </p>

<pre><code class="language-text">valid_referers none | blocked | server_names | string;

// 参数详情：
none: &quot;Referer&quot; 来源头部为空的情况
blocked: &quot;Referer&quot; 来源头部不为空，但是里面的值被代理或防火墙删除了，这些值都不以http:// https://开头
server_names:  &quot;Referer&quot; 来源头部包含当前的server_names
</code></pre>

<p>简单示例：</p>

<pre><code class="language-text">location ~ .*\.(gif|jpg|png|flv|swf|rar|zip)$
{
    valid_referers none blocked lilaiqun.com *.lilaiqun.com;
    if ($invalid_referer) 
    {
        #return 403;
        rewite ^/ http://www.lilaiqun.com/403.jpg;
    }
}
</code></pre>

<h2 id="toc_1">2.使用加密签名</h2>

<p>使用第三方模块HttpAccessKeyModule实现Nginx防盗链<br/>
accesskey on|off 模块开关<br/>
accesskey_hashmethod md5|sha-1 签名加密方式<br/>
accesskey_arg GET参数名称<br/>
accesskey_signature 加密规则</p>

<pre><code class="language-text">location ~ .*\.(gif|jpg|png|flv|swf|rar|zip)$
{
    accesskey on;
    accesskey_hashmethod md5;
    accesskey_arg &quot;key&quot;;
    accesskey_signature &quot;mypass$remote_addr&quot;;
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高并发结构]]></title>
    <link href="blog.lilaiqun.com/15700944894509.html"/>
    <updated>2019-10-03T17:21:29+08:00</updated>
    <id>blog.lilaiqun.com/15700944894509.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>并发：相同时间点，有多少个访问同时到来。一个系统日PV在千万以上，有可能是一个高并发系统<br/>
QPS：每秒钟请求或者查询的数量，每秒响应的请求量<br/>
吞吐量：单位时间内处理的请求数量</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">高并发的问题，我们具体该关心什么？</h2>

<p>（总PV数 * 0.8）/ (6*3600 * 0.2) = 峰值每秒请求数（QPS）<br/>
80%的访问量集中在20%的时间</p>

<h2 id="toc_1">高并发解决方案案例</h2>

<p>流量优化： <a href="15700981798015.html">Web资源防盗链</a><br/>
前端优化： <a href="15700996704794.html">减少HTTP请求</a>、添加异步请求、<a href="15701010542234.html">浏览器缓存和数据压缩</a>、CDN加速、建立图片服务器<br/>
服务端优化： <a href="15701041292991.html">页面静态化</a>、并发处理（多线程异步、队列异步处理）<br/>
数据库优化： <a href="15701558070255.html">数据库缓存</a>、分库分表、分区操作、读写分离<br/>
Web服务器优化： 负载均衡</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何解决消息队列中的延迟]]></title>
    <link href="blog.lilaiqun.com/15700896906629.html"/>
    <updated>2019-10-03T16:01:30+08:00</updated>
    <id>blog.lilaiqun.com/15700896906629.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问： 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">面试官心里分析</h2>

<p>你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了，或者消费的极其极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如rabbitmq设置了消息过期时间后就没了怎么办？</p>

<p>所以就这事儿，其实线上挺常见的，一般不出，一出就是大case，一般常见于，举个例子，消费端每次消费之后要写mysql，结果mysql挂了，消费端hang那儿了，不动了。或者是消费端出了个什么叉子，导致消费速度极其慢。</p>

<h2 id="toc_1">面试题分析</h2>

<p>关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在mq里积压，现在事故了，慌了</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息的顺序性？]]></title>
    <link href="blog.lilaiqun.com/15700882317067.html"/>
    <updated>2019-10-03T15:37:11+08:00</updated>
    <id>blog.lilaiqun.com/15700882317067.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问：如何保证消息的顺序性</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">面试题剖析：</h2>

<p>我举个例子，我们以前做过一个mysql binlog同步的系统，压力还是非常大的，日同步数据要达到上亿。mysql -&gt; mysql，常见的一点在于说大数据team，就需要同步一个mysql库过来，对公司的业务系统的数据做各种复杂的操作。</p>

<p>你在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。</p>

<p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p>

<p>先看看顺序会错乱的俩场景</p>

<p>（1）rabbitmq：一个queue，多个consumer，这不明显乱了<br/>
（2）kafka：一个topic，一个partition，一个consumer，<strong>内部多线程</strong>，这不也明显乱了</p>

<p><img src="http://images.lilaiqun.com/15700893668371.jpg" alt="kafka消息错乱"/></p>

<p>那如何保证消息的顺序性呢？简单简单</p>

<p>（1）rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理</p>

<p>（2）kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可</p>

<p><img src="http://images.lilaiqun.com/15700892292208.jpg" alt="kafka消息错乱解决方案"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息队列的可靠性（消息不丢）]]></title>
    <link href="blog.lilaiqun.com/15700740718336.html"/>
    <updated>2019-10-03T11:41:11+08:00</updated>
    <id>blog.lilaiqun.com/15700740718336.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问： 如何保证消息的可靠性传输（如何处理消息丢失的问题）？</p>
</blockquote>

<span id="more"></span><!-- more -->

<p>如果说你这个是用mq来传递非常核心的消息，比如说计费，扣费的一些消息，因为我以前设计和研发过一个公司非常核心的广告平台，计费系统，计费系统是很重的一个业务，操作是很耗时的。所以说广告系统整体的架构里面，实际上是将计费做成异步化的，然后中间就是加了一个MQ。</p>

<p>我们当时为了确保说这个MQ传递过程中绝对不会把计费消息给弄丢，花了很多的精力。广告主投放了一个广告，明明说好了，用户点击一次扣费1块钱。结果要是用户动不动点击了一次，扣费的时候搞的消息丢了，我们公司就会不断的少几块钱，几块钱，积少成多，这个就对公司是一个很大的损失。</p>

<h2 id="toc_0">面试题剖析</h2>

<p>这个丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了。咱们从rabbitmq和kafka分别来分析一下吧</p>

<p>rabbitmq这种mq，一般来说都是承载公司的核心业务的，数据是绝对不能弄丢的</p>

<h3 id="toc_1">1.Rabbitmq</h3>

<p><img src="http://images.lilaiqun.com/15700881424752.jpg" alt=""/></p>

<p>1）生产者弄丢了数据</p>

<p>生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。</p>

<p>此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。</p>

<p>所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p>

<p>事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。</p>

<p>所以一般在生产者这块避免数据丢失，都是用confirm机制的。</p>

<p>2）rabbitmq弄丢了数据</p>

<p>就是rabbitmq自己弄丢了数据，这个你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。</p>

<p>设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。</p>

<p>而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。</p>

<p>哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。</p>

<p>3）消费端弄丢了数据</p>

<p>rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。</p>

<p>这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。</p>

<h3 id="toc_2">2.kafka</h3>

<p><img src="http://images.lilaiqun.com/15700881304080.jpg" alt=""/></p>

<p>1）消费端弄丢了数据</p>

<p>唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p>

<p>这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p>

<p>生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。</p>

<p>然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了</p>

<p>2）kafka弄丢了数据</p>

<p>这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。</p>

<p>生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了</p>

<p>所以此时一般是要求起码设置如下4个参数：</p>

<p>给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本</p>

<p>在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧</p>

<p>在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了</p>

<p>在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了</p>

<p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失</p>

<p>3）生产者会不会弄丢数据</p>

<p>如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息不被重复消费（消费时的幂等性）]]></title>
    <link href="blog.lilaiqun.com/15700210659906.html"/>
    <updated>2019-10-02T20:57:45+08:00</updated>
    <id>blog.lilaiqun.com/15700210659906.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="http://images.lilaiqun.com/%E5%9B%BE%E7%89%87.png" alt="Kafka图示"/><br/>
<img src="http://images.lilaiqun.com/15700216386343.jpg" alt=""/></p>

<p>回答这个问题，首先你别听到重复消息这个事儿，就一无所知吧，你先大概说一说可能会有哪些重复消费的问题。</p>

<p>首先就是比如rabbitmq、rocketmq、kafka，都有可能会出现消费重复消费的问题，正常。因为这问题通常不是mq自己保证的，是给你保证的。然后我们挑一个kafka来举个例子，说说怎么重复消费吧。</p>

<p>kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。</p>

<p>但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。</p>

<p><strong>其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。</strong></p>

<p>给你举个例子吧。假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，不就保留了一条数据？</p>

<p>一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性</p>

<p>幂等性，我通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。</p>

<p>那所以第二个问题来了，怎么保证消息队列消费的幂等性？</p>

<p>其实还是得结合业务来思考，我这里给几个思路：</p>

<p>（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧</p>

<p>（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性</p>

<p>（3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</p>

<p>还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据</p>

<p>如何保证MQ的消费是幂等性的，需要结合具体的业务来看</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息队列的高可用啊？]]></title>
    <link href="blog.lilaiqun.com/15700185588826.html"/>
    <updated>2019-10-02T20:15:58+08:00</updated>
    <id>blog.lilaiqun.com/15700185588826.html</id>
    <content type="html"><![CDATA[
<p>问题：</p>

<pre><code class="language-text">MQ的缺点：系统可用性降低。接下来围绕MQ的缺点怎么解决。

MQ的高可用性怎么保证？ 
</code></pre>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1. RabbitMQ的高可用</h2>

<p>RabbitMQ比较有代表性，因为是基于主从架构</p>

<p>3种模式：<strong>单机模式，普通集群模式，镜像集群模式</strong></p>

<p>1）单机模式</p>

<p>就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式</p>

<p>2）普通集群模式</p>

<p><img src="http://images.lilaiqun.com/15700196661169.jpg" alt=""/></p>

<p>意思就是在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。</p>

<p>这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。</p>

<p>而且如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。</p>

<p>所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作。</p>

<p>3）镜像集群模式</p>

<p><img src="http://images.lilaiqun.com/15700197102596.jpg" alt=""/></p>

<p>这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。</p>

<p>这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue</p>

<p>那么怎么开启这个镜像集群模式呢？我这里简单说一下，避免面试人家问你你不知道，其实很简单rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p>

<h2 id="toc_1">2. kakfa</h2>

<p><img src="http://images.lilaiqun.com/15700200076415.jpg" alt=""/></p>

<p>kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。</p>

<p>这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。</p>

<p>实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。</p>

<p>kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。</p>

<p>kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。</p>

<p>这么搞，就有所谓的高可用性了，因为如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。</p>

<p>写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）</p>

<p>消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。</p>

<p>实际上这块机制，讲深了，是可以非常之深入的，但是我还是回到我们这个课程的主题和定位，聚焦面试，至少你听到这里大致明白了kafka是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要遇上面试官确实是kafka高手，深挖了问，那你只能说不好意思，太深入的你没研究过。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[消息队列技术选型]]></title>
    <link href="blog.lilaiqun.com/15700030762829.html"/>
    <updated>2019-10-02T15:57:56+08:00</updated>
    <id>blog.lilaiqun.com/15700030762829.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1.为何使用消息队列</h2>

<p><code>解耦、异步、消峰</code></p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">2.缺点</h2>

<ol>
<li>可用性降低，系统太依赖消息队列<br/></li>
<li>增加系统复杂性，发送多次消息<br/></li>
<li>一致性问题，消息发送顺序错误，导致结果错误<br/></li>
</ol>

<table>
<thead>
<tr>
<th></th>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>RocketMQ</th>
<th>Kafka</th>
</tr>
</thead>

<tbody>
<tr>
<td>吞吐量</td>
<td>万级</td>
<td>万级</td>
<td>10万级</td>
<td>10万级</td>
</tr>
<tr>
<td>topic数量对吞吐量影响</td>
<td>万级</td>
<td>万级</td>
<td>topic可以达到几千级别，吞吐量会小幅度下降</td>
<td>topic从几十到几百个的时候，吞吐量会大幅度下降。 所以同等机器下，kafka尽量保证topic数量不要过多</td>
</tr>
<tr>
<td>时效性</td>
<td>ms级</td>
<td>微妙级，延迟最低</td>
<td>ms级</td>
<td>ms以内</td>
</tr>
<tr>
<td>可用性</td>
<td>搞，基于主从架构实现高可用</td>
<td>高，基于主从架构</td>
<td>非常高，分布式</td>
<td>非常高，分布式，一个数据多个副本，不会丢失数据</td>
</tr>
<tr>
<td>消息可靠性</td>
<td>低概率丢失</td>
<td></td>
<td>通过参数优化配置，0丢失</td>
<td>通过参数优化配置，0丢失</td>
</tr>
<tr>
<td>功能支持</td>
<td>MQ功能极其完备</td>
<td>自带后台适合小型公司，社区活跃，基于erlang开发，开发能力强，延迟很低</td>
<td>MQ功能比较完善，还是分布式的，扩展性好</td>
<td>支持简单MQ功能，在大数据领域的实时计算以及日志采集被大规模使用</td>
</tr>
<tr>
<td>优劣势</td>
<td>非常成熟，功能强大</td>
<td>erlang开发，性能好，延迟低</td>
<td>接口简单</td>
<td>吞吐量搞，大数据领域的日志采集</td>
</tr>
</tbody>
</table>

<h2 id="toc_2">RabbitMq</h2>

<h2 id="toc_3">MQ</h2>

<h2 id="toc_4">Redis</h2>

<h2 id="toc_5">Kafka</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[目录接口]]></title>
    <link href="blog.lilaiqun.com/15700028122851.html"/>
    <updated>2019-10-02T15:53:32+08:00</updated>
    <id>blog.lilaiqun.com/15700028122851.html</id>
    <content type="html"><![CDATA[
<p>编译与执行<br/>
词法、语法分析基本原理<br/>
抽象语法书<br/>
Zend虚拟机</p>

<h2 id="toc_0">基本语法与扩展编写</h2>

<p><a href="#">各类基础语法的实现</a><br/>
<a href="#">手把手编写一个PHP扩展</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[面试官：给我讲一下分库分表方案]]></title>
    <link href="blog.lilaiqun.com/15647135075311.html"/>
    <updated>2019-08-02T10:38:27+08:00</updated>
    <id>blog.lilaiqun.com/15647135075311.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<blockquote>
<p>作者：尜尜人物<br/>
  链接：<a href="https://www.cnblogs.com/littlecharacter/p/9342129.html">https://www.cnblogs.com/littlecharacter/p/9342129.html</a></p>
</blockquote>

<ul>
<li>
<a href="#toc_0">一、数据库瓶颈</a>
<ul>
<li>
<a href="#toc_1">1、IO瓶颈</a>
</li>
<li>
<a href="#toc_2">2、CPU瓶颈</a>
</li>
</ul>
</li>
<li>
<a href="#toc_3">二、分库分表</a>
<ul>
<li>
<a href="#toc_4">1、水平分库</a>
</li>
<li>
<a href="#toc_5">2、水平分表</a>
</li>
<li>
<a href="#toc_6">3、垂直分库</a>
</li>
<li>
<a href="#toc_7">4、垂直分表</a>
</li>
</ul>
</li>
<li>
<a href="#toc_8">三、分库分表工具</a>
</li>
<li>
<a href="#toc_9">四、分库分表步骤</a>
</li>
<li>
<a href="#toc_10">五、分库分表问题</a>
<ul>
<li>
<a href="#toc_11">1. 非partition key的查询问题（水平分库分表，拆分策略为常用的hash法）</a>
</li>
<li>
<a href="#toc_12">2、非partition key跨库跨表分页查询问题（水平分库分表，拆分策略为常用的hash法）</a>
</li>
<li>
<a href="#toc_13">3、扩容问题（水平分库分表，拆分策略为常用的hash法）</a>
</li>
</ul>
</li>
<li>
<a href="#toc_14">六、分库分表总结</a>
</li>
<li>
<a href="#toc_15">七、分库分表示例</a>
</li>
</ul>


<h2 id="toc_0">一、数据库瓶颈</h2>

<p>不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。接下来就可以想象了吧（并发量、吞吐量、崩溃）。</p>

<h3 id="toc_1">1、IO瓶颈</h3>

<p>第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -&gt; 分库和垂直分表。<br/>
第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -&gt; 分库。</p>

<h3 id="toc_2">2、CPU瓶颈</h3>

<p>第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作 -&gt; SQL优化，建立合适的索引，在业务Service层进行业务计算。<br/>
第二种：单表数据量太大，查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈 -&gt; 水平分表。</p>

<h2 id="toc_3">二、分库分表</h2>

<h3 id="toc_4">1、水平分库</h3>

<p><img src="http://images.lilaiqun.com/15647137481060.jpg" alt=""/></p>

<ol>
<li><p>概念：以字段为依据，按照一定策略（hash、range等），将一个库中的数据拆分到多个库中。</p></li>
<li><p>结果：</p></li>
<li><p>每个库的结构都一样；</p></li>
<li><p>每个库的数据都不一样，没有交集；</p></li>
<li><p>所有库的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量上来了，分表难以根本上解决问题，并且还没有明显的业务归属来垂直分库。</p></li>
<li><p>分析：库多了，io和cpu的压力自然可以成倍缓解。</p></li>
</ol>

<h3 id="toc_5">2、水平分表</h3>

<p><img src="http://images.lilaiqun.com/15647137986218.jpg" alt=""/></p>

<ol>
<li><p>概念：以字段为依据，按照一定策略（hash、range等），将一个表中的数据拆分到多个表中。</p></li>
<li><p>结果：<br/>
每个表的结构都一样；<br/>
每个表的数据都不一样，没有交集；<br/>
所有表的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量并没有上来，只是单表的数据量太多，影响了SQL效率，加重了CPU负担，以至于成为瓶颈。</p></li>
<li><p>分析：表的数据量少了，单次SQL执行效率高，自然减轻了CPU的负担。</p></li>
</ol>

<h3 id="toc_6">3、垂直分库</h3>

<p><img src="http://images.lilaiqun.com/15647138213351.jpg" alt=""/></p>

<ol>
<li>概念：以表为依据，按照业务归属不同，将不同的表拆分到不同的库中。</li>
<li>结果：</li>
<li>每个库的结构都不一样；</li>
<li>每个库的数据也不一样，没有交集；</li>
<li><p>所有库的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量上来了，并且可以抽象出单独的业务模块。</p></li>
<li><p>分析：到这一步，基本上就可以服务化了。例如，随着业务的发展一些公用的配置表、字典表等越来越多，这时可以将这些表拆到单独的库中，甚至可以服务化。再有，随着业务的发展孵化出了一套业务模式，这时可以将相关的表拆到单独的库中，甚至可以服务化。</p></li>
</ol>

<h3 id="toc_7">4、垂直分表</h3>

<p><img src="http://images.lilaiqun.com/15647138576584.jpg" alt=""/></p>

<ol>
<li><p>概念：以字段为依据，按照字段的活跃性，将表中字段拆到不同的表（主表和扩展表）中。</p></li>
<li><p>结果：</p></li>
<li><p>每个表的结构都不一样；</p></li>
<li><p>每个表的数据也不一样，一般来说，每个表的字段至少有一列交集，一般是主键，用于关联数据；</p></li>
<li><p>所有表的并集是全量数据；</p></li>
<li><p>场景：系统绝对并发量并没有上来，表的记录并不多，但是字段多，并且热点数据和非热点数据在一起，单行数据所需的存储空间较大。以至于数据库缓存的数据行减少，查询时会去读磁盘数据产生大量的随机读IO，产生IO瓶颈。</p></li>
<li><p>分析：可以用列表页和详情页来帮助理解。垂直分表的拆分原则是将热点数据（可能会冗余经常一起查询的数据）放在一起作为主表，非热点数据放在一起作为扩展表。这样更多的热点数据就能被缓存下来，进而减少了随机读IO。拆了之后，要想获得全部数据就需要关联两个表来取数据。但记住，千万别用join，因为join不仅会增加CPU负担并且会讲两个表耦合在一起（必须在一个数据库实例上）。关联数据，应该在业务Service层做文章，分别获取主表和扩展表数据然后用关联字段关联得到全部数据。</p></li>
</ol>

<h2 id="toc_8">三、分库分表工具</h2>

<ol>
<li>sharding-sphere：jar，前身是sharding-jdbc；</li>
<li>TDDL：jar，Taobao Distribute Data Layer；</li>
<li>Mycat：中间件。</li>
</ol>

<p>注：工具的利弊，请自行调研，官网和社区优先。</p>

<h2 id="toc_9">四、分库分表步骤</h2>

<p>根据容量（当前容量和增长量）评估分库或分表个数 -&gt; 选key（均匀）-&gt; 分表规则（hash或range等）-&gt; 执行（一般双写）-&gt; 扩容问题（尽量减少数据的移动）。</p>

<h2 id="toc_10">五、分库分表问题</h2>

<h3 id="toc_11">1. 非partition key的查询问题（水平分库分表，拆分策略为常用的hash法）</h3>

<p>除了partition key只有一个非partition key作为条件查询</p>

<p><strong>映射法</strong><br/>
<img src="http://images.lilaiqun.com/15647140231654.jpg" alt=""/></p>

<p><strong>基因法</strong><br/>
<img src="http://images.lilaiqun.com/15647140318991.jpg" alt=""/></p>

<p>注：写入时，基因法生成user_id，如图。关于xbit基因，例如要分8张表，23=8，故x取3，即3bit基因。根据user_id查询时可直接取模路由到对应的分库或分表。根据user_name查询时，先通过user_name_code生成函数生成user_name_code再对其取模路由到对应的分库或分表。id生成常用<strong>snowflake算法</strong>。</p>

<ol>
<li>端上除了partition key不止一个非partition key作为条件查询</li>
</ol>

<p><strong>映射法</strong><br/>
<img src="http://images.lilaiqun.com/15647140607030.jpg" alt=""/></p>

<p><strong>冗余法</strong><br/>
<img src="http://images.lilaiqun.com/15647140694844.jpg" alt=""/></p>

<p>注：按照order_id或buyer_id查询时路由到db_o_buyer库中，按照seller_id查询时路由到db_o_seller库中。感觉有点本末倒置！有其他好的办法吗？改变技术栈呢？</p>

<p>3、后台除了partition key还有各种非partition key组合条件查询</p>

<p><strong>NoSQL法</strong><br/>
<img src="http://images.lilaiqun.com/15647150946637.jpg" alt=""/></p>

<p><strong>冗余法</strong><br/>
<img src="http://images.lilaiqun.com/15647151004264.jpg" alt=""/></p>

<h3 id="toc_12">2、非partition key跨库跨表分页查询问题（水平分库分表，拆分策略为常用的hash法）</h3>

<p>注：用NoSQL法解决（ES等）。</p>

<h3 id="toc_13">3、扩容问题（水平分库分表，拆分策略为常用的hash法）</h3>

<p>1、水平扩容库（升级从库法<br/>
<img src="http://images.lilaiqun.com/15647151413436.jpg" alt=""/></p>

<p>注：扩容是成倍的。</p>

<p>2、水平扩容表（双写迁移法）<br/>
<img src="http://images.lilaiqun.com/15647151512396.jpg" alt=""/></p>

<p>第一步：（同步双写）应用配置双写，部署；<br/>
第二步：（同步双写）将老库中的老数据复制到新库中；<br/>
第三步：（同步双写）以老库为准校对新库中的老数据；<br/>
第四步：（同步双写）应用去掉双写，部署；</p>

<p>注：双写是通用方案。</p>

<h2 id="toc_14">六、分库分表总结</h2>

<p>分库分表，首先得知道瓶颈在哪里，然后才能合理地拆分（分库还是分表？水平还是垂直？分几个？）。且不可为了分库分表而拆分。</p>

<p>1、选key很重要，既要考虑到拆分均匀，也要考虑到非partition key的查询。<br/>
2、只要能满足需求，拆分规则越简单越好。</p>

<h2 id="toc_15">七、分库分表示例</h2>

<p>示例GitHub地址：<a href="https://github.com/littlecharacter4s/study-sharding">https://github.com/littlecharacter4s/study-sharding</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Excel制作二维码]]></title>
    <link href="blog.lilaiqun.com/15644556452076.html"/>
    <updated>2019-07-30T11:00:45+08:00</updated>
    <id>blog.lilaiqun.com/15644556452076.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="http://images.lilaiqun.com/Excel%E5%88%B6%E4%BD%9C%E4%BA%8C%E7%BB%B4%E7%A0%81.png" alt="Excel制作二维码"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第三篇 Swoole WebSocket 的应用]]></title>
    <link href="blog.lilaiqun.com/15643711302986.html"/>
    <updated>2019-07-29T11:32:10+08:00</updated>
    <id>blog.lilaiqun.com/15643711302986.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<blockquote>
<p>转自：公众号 - 新亮笔记</p>
</blockquote>

<h2 id="toc_0">概述</h2>

<p>什么是 WebSocket ？</p>

<blockquote>
<p>WebSocket 是一种在单个TCP连接上进行全双工通信的协议。</p>
</blockquote>

<p>WebSocket 使得客户端和服务器之间的数据交换变得更加简单，允许服务端主动向客户端推送数据。</p>

<p>在 WebSocket API 中，浏览器和服务器只需要完成一次握手，两者之间就直接可以创建持久性的连接，并进行双向数据传输。</p>

<p>我们利用 WebSocket 进行及时通讯，今天实现一个 视频弹幕效果。</p>

<p>实现弹幕其实就和群聊类似，将消息推送给所有的客户端，只不过前端的展示所有不同。</p>

<p>本地版本：</p>

<p>后端 PHP 7.2.6、Swoole 4.3.1。</p>

<p>前端 HTML5 WebSocket、Canvas。</p>

<p>废话不多说，先看效果。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第二篇 Swoole Task 的应用]]></title>
    <link href="blog.lilaiqun.com/15639348696355.html"/>
    <updated>2019-07-24T10:21:09+08:00</updated>
    <id>blog.lilaiqun.com/15639348696355.html</id>
    <content type="html"><![CDATA[
<p>投递一个异步任务到task_worker池中。此函数是非阻塞的，执行完毕会立即返回。Worker进程可以继续处理新的请求。使用Task功能，必须先设置 task_worker_num，并且必须设置Server的onTask和onFinish事件回调函数。</p>

<span id="more"></span><!-- more -->

<blockquote>
<p>转自：公众号 - 新亮笔记</p>
</blockquote>

<h1 id="toc_0">一代码</h1>

<h2 id="toc_1">server.php</h2>

<pre><code class="language-php">&lt;?php
class Server
{
    private $serv;
    public function __construct()
    {
        $this-&gt;serv = new swoole_server(&#39;0.0.0.0&#39;, 9501;
        $this-&gt;serv-&gt;set([
            &#39;worker_num&#39; =&gt; 2,  //开启2个worker进程
            &#39;max_request&#39; =&gt; 4, //每个worker进程 max_request设置为4次
            &#39;task_worker_num&#39; =&gt; 4, //开启4个task进程
            &#39;dispatch_mode&#39; =&gt; 2,   //数据包分发策略 - 固定模式
        ]);
        $this-&gt;serv-&gt;on(&#39;Start&#39;, [$this, &#39;onStart&#39;]);
        $this-&gt;serv-&gt;on(&#39;Connect&#39;, [$this, &#39;onConnect&#39;]);
        $this-&gt;serv-&gt;on(&quot;Receive&quot;, [$this, &#39;onReceive&#39;]);
        $this-&gt;serv-&gt;on(&quot;Close&quot;, [$this, &#39;onClose&#39;]);
        $this-&gt;serv-&gt;on(&quot;Task&quot;, [$this, &#39;onTask&#39;]);
        $this-&gt;serv-&gt;on(&quot;Finish&quot;, [$this, &#39;onFinish&#39;]);
        $this-&gt;serv-&gt;start();
    }

    public function onStart($serv)
    {
        echo &quot;#### onStart ####&quot; . PHP_EOL;
        echo &quot;SWOOLE &quot; . SWOOLE_VERSION . &quot; 服务已启动&quot; . PHP_EOL;
        echo &quot;master_pid: {$serv-&gt;master_pid}&quot; . PHP_EOL;
        echo &quot;manager_pid: {$serv-&gt;manager_pid}&quot; . PHP_EOL;
        echo &quot;########&quot; . PHP_EOL . PHP_EOL;
    }

    public function onConnect($serv, $fd) {
        echo &quot;#### onConnect ####&quot; . PHP_EOL;
        echo &quot;客户端:&quot; . $fd . &quot; 已连接&quot; . PHP_EOL;
        echo &quot;########&quot; . PHP_EOL;
    }

    public function onReceive($serv, $fd, $from_id, $data) {
        echo &quot;#### onReceive ####&quot; . PHP_EOL;
        echo &quot;worker_pid: {$serv-&gt;worker_pid}&quot; . PHP_EOL;
        echo &quot;客户端:{$fd} 发来的Email:{$data}&quot; . PHP_EOL;
        $param = [
            &#39;fd&#39; =&gt; $fd,
            &#39;email&#39; =&gt; $data
        ];
        $rs = $serv-&gt;task(json_encode($param));
        if ($rs === false) {
            echo &quot;任务分配失败 Task &quot; . $rs . PHP_EOL;
        } else {
            echo &quot;任务分配成功 Task &quot; . $rs . PHP_EOL;
        }
        echo &quot;########&quot; . PHP_EOL . PHP_EOL;
    }

    public function onTask($serv, $task_id, $from_id, $data) {
        echo &quot;#### onTask ####&quot; . PHP_EOL;
        echo &quot;#{$serv-&gt;worker_id} onTask: [PID={$serv-&gt;worker_pid}]: task_id={$task_id}&quot; . PHP_EOL;
        //业务代码
        for ($i = 1; $i &lt;= 5; $i++) {
            sleep(2);
            echo &quot;Task {$task_id} 已完成了 {$i}/5 的任务&quot; . PHP_EOL;
        }
        $data_arr = json_decode($data, true);

        $serv-&gt;send($data_arr[&#39;fd&#39;], &#39;Email:&#39; . $data_arr[&#39;email&#39;] . &#39;,发送成功&#39;);
        $serv-&gt;finish($data);
        echo &quot;########&quot; . PHP_EOL;
    }

    public function onFinish($serv, $task_id, $data) {
        echo &quot;#### onFinish ####&quot; . PHP_EOL;
        echo &quot;Task {$task_id} 已完成&quot; . PHP_EOL;
        echo &quot;########&quot; . PHP_EOL;
    }

    public function onClose($serv, $fd) {
        echo &quot;Client Close.&quot; . PHP_EOL;
    }
}

$server = new Server();
</code></pre>

<p>client.php</p>

<pre><code class="language-php">&lt;?php
class Client
{   
    private $client;
    
    public function __construct() {
        $this-&gt;client = new swoole_client(SWOOLE_SOCK_TCP, SWOOLE_SOCK_ASYNC);
        $this-&gt;client-&gt;on(&#39;Connect&#39;, [$this, &#39;onConnect&#39;]);
        $this-&gt;client-&gt;on(&#39;Receive&#39;, [$this, &#39;onReceive&#39;]);
        $this-&gt;client-&gt;on(&#39;Close&#39;, [$this, &#39;onClose&#39;]);
        $this-&gt;client-&gt;on(&#39;Error&#39;, [$this, &#39;onError&#39;]);
    }
    
    public function connect() {
        if (!$fp = $this-&gt;client-&gt;connect(&#39;127.0.0.1&#39;, 9501, 1)) {
            echo &quot;Error: {$fp-&gt;errMsg}[{$fp-&gt;errCode}]&quot; . PHP_EOL;
            return;
        }
    }

    public function onConnect($cli) {
        fwrite(STDOUT, &quot;输入Email:&quot;);
        swoole_event_add(STDIN, function(){
            fwrite(STDOUT, &quot;输入内容:&quot;);
            $msg = trim(fgets(STDIN));
            $this-&gt;send($msg);
        });
    }

    public function onReceive($cli, $data) {
        echo PHP_EOL . &quot;Received: &quot; . $data . PHP_EOL; 
    }

    public function send($data) {
        $this-&gt;client-&gt;send($data);
    }

    public function onClose($cli) {
        echo &quot;Client close connection&quot; . PHP_EOL; 
    }

    public function onError() {

    }
}


$client = new Client();
$client-&gt;connect();
</code></pre>

<h2 id="toc_2">输出</h2>

<pre><code class="language-text"># 1.启动服务端
&gt; php server.php

#### onStart ####
SWOOLE 1.10.4 服务已启动
master_pid: 4258
manager_pid: 4259
########

# 2.启动客户端
&gt; php client.php

输入Email: aaa@bb.com

# 3.服务端接收到请求

#### onConnect ####
客户端:1 已连接
########
#### onReceive ####
worker_pid: 4264
客户端:1 发来的Email:aaa@bb.com
任务分配成功 Task 0
########

#### onTask ####
#2 onTask: [PID=4260]: task_id=0
Task 0 已完成了 1/5 的任务
Task 0 已完成了 2/5 的任务
Task 0 已完成了 3/5 的任务
Task 0 已完成了 4/5 的任务
Task 0 已完成了 5/5 的任务
########
#### onFinish ####
Task 0 已完成
########

# 4.客户端收到消息

Received: Email:aaa@bb.com,发送成功
</code></pre>

<h2 id="toc_3">查看运行中的进程</h2>

<p>总共8个进程（1个master进程、1个manager进程、4个task进程、2个worker进程）</p>

<pre><code class="language-text">&gt; ps -ef|grep &#39;server.php&#39; | grep -v &#39;grep&#39;

501  4258   670   0  1:54下午 ttys003    0:06.90 php server.php
501  4259  4258   0  1:54下午 ttys003    0:00.00 php server.php
501  4260  4259   0  1:54下午 ttys003    0:00.01 php server.php
501  4261  4259   0  1:54下午 ttys003    0:00.00 php server.php
501  4262  4259   0  1:54下午 ttys003    0:00.00 php server.php
501  4263  4259   0  1:54下午 ttys003    0:00.00 php server.php
501  4264  4259   0  1:54下午 ttys003    0:00.01 php server.php
501  4265  4259   0  1:54下午 ttys003    0:00.00 php server.php
</code></pre>

<p>master进程：4258<br/>
manager进程：4259</p>

<h1 id="toc_4">二为什么执行了5次后，worker进程号发生了改变？</h1>

<p>因为我们设了置worker进程的max_request=4，一个worker进程在完成最大请求次数任务后将自动退出，进程退出会释放所有的内存和资源，这样的机制主要是解决PHP进程内存溢出的问题。</p>

<h1 id="toc_5">三当task执行任务异常，我们kill一个task进程，会再新增一个吗？</h1>

<p>会。</p>

<h1 id="toc_6">四如何设置 task_worker_num ？</h1>

<p>最大值不得超过 SWOOLE_CPU_NUM * 1000。<br/>
查看本机 CPU 核数：</p>

<pre><code class="language-text">&gt; php -a
&gt; echo swoole_cpu_num();
</code></pre>

<p>根据项目的任务量决定的，比如：1秒会产生200个任务，执行每个任务需要500ms。<br/>
想在1s中执行完成200个任务，需要100个task进程。<br/>
100 = 200/(1/0.5)</p>

<h1 id="toc_7">五如何设置 worker_num ？</h1>

<p>默认设置为本机的CPU核数，最大不得超过 SWOOLE_CPU_NUM * 1000。<br/>
比如：1个请求耗时10ms，要提供1000QPS的处理能力，那就必须配置10个进程。<br/>
10 = 0.01*1000<br/>
假设每个进程占用40M内存，10个进程就需要占用400M的内存。</p>

<p>扩展</p>

<ul>
<li>Server-&gt;taskwait</li>
<li>Server-&gt;taskWaitMulti</li>
<li>Server-&gt;taskCo</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[第一篇 Swoole Timer 的应用]]></title>
    <link href="blog.lilaiqun.com/15638622569963.html"/>
    <updated>2019-07-23T14:10:56+08:00</updated>
    <id>blog.lilaiqun.com/15638622569963.html</id>
    <content type="html"><![CDATA[
<p>应用场景:</p>

<ol>
<li>每天凌晨跑业务脚本</li>
<li>设计一个用WEB界面管理管理定时任务的系统。</li>
</ol>

<span id="more"></span><!-- more -->

<blockquote>
<p>转自：公众号 - 新亮笔记</p>
</blockquote>

<h2 id="toc_0">你好，Swoole</h2>

<p>PHP 的协程高性能网络通信引擎，使用 C/C++ 语言编写，提供了多种通信协议的网络服务器和客户端模块。</p>

<p>Swoole 可应用于互联网、移动通信、企业软件、网络游戏、物联网、车联网、智能家庭等领域。</p>

<p>学习 Swoole 之前，最好先了解下底层知识，比如，线程/进程、IO、TCP/IP协议 等。</p>

<p>推荐大家读一下《Linux 高性能服务器编程》这本书。</p>

<p>这篇文章主要分享 Timer 毫秒精度的定时器。</p>

<p>本地版本：PHP 7.2.6、Swoole 4.3.1。</p>

<h2 id="toc_1">Timer</h2>

<p>主要有三个方法：</p>

<p>swoole_timer_tick 间隔的时钟控制器</p>

<p>swoole_timer_after 指定的时间后执行</p>

<p>swoole_timer_clear 删除定时器</p>

<p>示例代码：</p>

<pre><code class="language-php">// 每隔3000ms触发一次
$timer_id = swoole_timer_tick(3000, function ($timer_id) {
    echo &quot;tick-&quot; . $timer_id . &quot; 3000ms-&quot; . date(&quot;Y-m-d H:i:s&quot;) . &quot;\n&quot;;
});

// 30000ms后删除定时器
swoole_timer_after(30000, function() use ($timer_id) {
    echo &quot;after 30000ms-&quot; . date(&quot;Y-m-d H:i:s&quot;) . &quot;\n&quot;;
    swoole_timer_clear($timer_id);
});
</code></pre>

<p>运行结果：</p>

<pre><code class="language-text">&gt; php timer.php

tick-1 3000ms-2019-07-23 06:23:51
tick-1 3000ms-2019-07-23 06:23:54
tick-1 3000ms-2019-07-23 06:23:57
after 30000ms-2019-07-23 06:23:57
</code></pre>

<h2 id="toc_2">应用场景</h2>

<h3 id="toc_3">一、每天凌晨跑业务脚本</h3>

<p>脚本中包括了请求其他业务方或第三方的接口，如果接口超时无响应或没有数据返回，需要进行重试。</p>

<p>重试机制为：每5隔分钟再发送一次请求，最多尝试5次，在5次内成功停止该任务，5次仍失败也停止该任务。</p>

<p>示例代码：</p>

<pre><code class="language-php">function requestUrl($url) {
    return false;
}

$apiUrl = &#39;&#39;;      // api地址
$exec_time = 0;    // 执行次数
swoole_timer_tick(6000, function($timer_id) use ($apiUrl, &amp;$exec_time) {
    $exec_time++;
    $result = requestUrl($apiUrl);
    echo date(&#39;Y-m-d H:i:s&#39;) . &quot; 执行任务中...(&quot; . $exec_time . &quot;)\n&quot;;
    if ($result) {
        // 业务代码
        swoole_timer_clear($timer_id);  // 停止定时器
        echo date(&#39;Y-m-d H:i:s&#39;) . &#39; 第（&#39; . $exec_time . &quot;）次请求接口任务执行成功\n&quot;;
    }else {
        if ($exec_time &gt;= 5) {
            swoole_timer_clear($timer_id);  // 停止定时器
            echo date(&#39;Y-m-d H:i:s&#39;) . &quot;请求接口失败，已失败5次，停止执行\n&quot;;
        } else {
            echo date(&#39;Y-m-d H:i:s&#39;) . &quot;请求接口失败，5分钟后再次尝试\n&quot;;
        }
    }
});
</code></pre>

<p>运行结果：</p>

<pre><code class="language-text">2019-07-23 08:50:08 执行任务中...(1)
2019-07-23 08:50:08请求接口失败，5分钟后再次尝试
2019-07-23 08:50:14 执行任务中...(2)
2019-07-23 08:50:14请求接口失败，5分钟后再次尝试
2019-07-23 08:50:20 执行任务中...(3)
2019-07-23 08:50:20请求接口失败，5分钟后再次尝试
2019-07-23 08:50:26 执行任务中...(4)
2019-07-23 08:50:26请求接口失败，5分钟后再次尝试
2019-07-23 08:50:32 执行任务中...(5)
2019-07-23 08:50:32请求接口失败，已失败5次，停止执行
</code></pre>

<h3 id="toc_4">二、设计一个用WEB界面管理管理定时任务的系统。</h3>

<p>Linux Crontab 最小时间粒度为分钟。</p>

<p>PHP Swoole 最小时间粒度为毫秒。</p>

<pre><code class="language-text">--------------
介绍一下时间配置

    0   1   2   3   4   5
    |   |   |   |   |   |
    |   |   |   |   |   +------ day of week (0 - 6) (Sunday=0)
    |   |   |   |   +------ month (1 - 12)
    |   |   |   +-------- day of month (1 - 31)
    |   |   +---------- hour (0 - 23)
    |   +------------ min (0 - 59)
    +-------------- sec (0-59)[可省略，如果没有0位,则最小时间粒度是分钟]
</code></pre>

<p>WEB界面管理</p>

<ul>
<li>登录、权限管理</li>
<li>任务管理（增删改查）</li>
<li>脚本机管理（机器IP地址）</li>
<li>任务日志</li>
</ul>

<p>项目地址</p>

<p><a href="https://github.com/osgochina/Donkey">https://github.com/osgochina/Donkey</a></p>

<p>三、比如，监控服务器状况。</p>

<p>参考文档<br/>
<a href="https://wiki.swoole.com/wiki/page/p-timer.html">https://wiki.swoole.com/wiki/page/p-timer.html</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Swoole 文章汇总]]></title>
    <link href="blog.lilaiqun.com/15638621513516.html"/>
    <updated>2019-07-23T14:09:11+08:00</updated>
    <id>blog.lilaiqun.com/15638621513516.html</id>
    <content type="html"><![CDATA[
<p>第一篇：<a href="15638622569963.html">Swoole Timer 的应用</a><br/>
第二篇：<a href="15639348696355.html">第二篇 Swoole Task 的应用</a></p>

<p>第三篇：Swoole WebSocket 的应用<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835004&amp;idx=1&amp;sn=d6789002ca8f919258ff21f0d8950fa9&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835004&amp;idx=1&amp;sn=d6789002ca8f919258ff21f0d8950fa9&amp;scene=21#wechat_redirect</a></p>

<span id="more"></span><!-- more -->

<p>第四篇：Swoole HTTP 的应用<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835017&amp;idx=1&amp;sn=0702c96c7cf0086b8c3d8da9b6bd8160&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835017&amp;idx=1&amp;sn=0702c96c7cf0086b8c3d8da9b6bd8160&amp;scene=21#wechat_redirect</a></p>

<p>第五篇：Swoole 多协议 多端口 的应用<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835038&amp;idx=1&amp;sn=9aa1dd1c76fbdfdae1c110f411c3f9e3&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835038&amp;idx=1&amp;sn=9aa1dd1c76fbdfdae1c110f411c3f9e3&amp;scene=21#wechat_redirect</a></p>

<p>第六篇：Swoole 整合成一个小框架<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835048&amp;idx=1&amp;sn=dc358c5fbc91a73faf4d04b1d45e71eb&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835048&amp;idx=1&amp;sn=dc358c5fbc91a73faf4d04b1d45e71eb&amp;scene=21#wechat_redirect</a></p>

<p>第七篇：Swoole RPC 的实现<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835054&amp;idx=1&amp;sn=26c27656b53923cc3f81a2aeb66c8d2b&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835054&amp;idx=1&amp;sn=26c27656b53923cc3f81a2aeb66c8d2b&amp;scene=21#wechat_redirect</a></p>

<p>第八篇：Swoole MySQL 连接池的实现<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835060&amp;idx=1&amp;sn=cc3e4ae8774338b56389ec3d29fbf69d&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835060&amp;idx=1&amp;sn=cc3e4ae8774338b56389ec3d29fbf69d&amp;scene=21#wechat_redirect</a></p>

<p>第九篇：Swoole Redis 连接池的实现<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835070&amp;idx=1&amp;sn=097c0972f92537ca2f8a68944b8fd8d5&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835070&amp;idx=1&amp;sn=097c0972f92537ca2f8a68944b8fd8d5&amp;scene=21#wechat_redirect</a></p>

<p>第十篇：压测 swoole_websocket_server 性能<br/>
<a href="https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835077&amp;idx=1&amp;sn=26e3db1a758409b7d2fdf82698094c47&amp;scene=21#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MjM5NDM4MDIwNw==&amp;mid=2448835077&amp;idx=1&amp;sn=26e3db1a758409b7d2fdf82698094c47&amp;scene=21#wechat_redirect</a></p>

]]></content>
  </entry>
  
</feed>
