<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[lilaiqun]]></title>
  <link href="blog.lilaiqun.com/atom.xml" rel="self"/>
  <link href="blog.lilaiqun.com/"/>
  <updated>2019-10-09T21:23:41+08:00</updated>
  <id>blog.lilaiqun.com/</id>
  <author>
    <name><![CDATA[]]></name>
    
  </author>
  <generator uri="http://www.mweb.im/">MWeb</generator>
  
  <entry>
    <title type="html"><![CDATA[awk统计访问日志access.log]]></title>
    <link href="blog.lilaiqun.com/15708513672196.html"/>
    <updated>2019-10-12T11:36:07+08:00</updated>
    <id>blog.lilaiqun.com/15708513672196.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">awk如何使用</h2>

<p>简单文本处理中，功能强大的awk命令。下文详细描述使用方法与示例:</p>

<p>语法：</p>

<pre><code class="language-bash">awk [选项参数] &#39;script&#39; var=value file(s)
或
awk [选项参数] -f scriptfile var=value file(s)
</code></pre>

<h2 id="toc_1">查看最新的访问日志</h2>

<pre><code class="language-bash">$ tail -n 50000 /data1/logs/nginx/access.log

0.012   0.012   10.135.12.135   508 127.0.0.1:9001  12/Oct/2019:10:49:17 +0800 aaadns.com   POST /api/pro HTTP/1.0
</code></pre>

<p><code>tail</code>查看文件结尾<br/>
<code>tail -n 50000</code> 查看文件倒数5万条记录</p>

<h2 id="toc_2">正则匹配访问url 包含字符串</h2>

<pre><code class="language-bash">$ awk &#39;{if($10~/separation/) {print substr($10,0,80)}}&#39;
</code></pre>

<p><code>$0</code> 表示整行记录<br/>
<code>$10</code>  /api/pro 以空格分隔的第10个字符串<br/>
<code>if ($10~/separation/)</code>  正则匹配第10个字符串是否包含separation<br/>
<code>substr($10, 0, 80)</code> 取第10个字符串中0到80个字符</p>

<h2 id="toc_3">url以特定字符分隔</h2>

<pre><code class="language-text">$ awk &#39;{split($0,a,&quot;?&quot;); print a[1]}
</code></pre>

<p><code>split($0,a,&quot;?&quot;)</code> $0表示输入的字符串，将输入字符串以?分隔，结果保存在a变量中</p>

<h2 id="toc_4">统计所有url的访问次数</h2>

<pre><code class="language-text">tail -n 50000 /data1/logs/nginx/access.log | awk &#39;{if($10~/separation/) {print $10}}&#39; | awk &#39;{split($0,a,&quot;?&quot;); print a[1]}&#39; |sort |uniq -c

   13 /separation/business/getBusin****
   94 /separation/house/com**
   13 /separation/house/de**
   4 /separation/housedetail/click***
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PHP底层的运行机制与原理]]></title>
    <link href="blog.lilaiqun.com/15707746132238.html"/>
    <updated>2019-10-11T14:16:53+08:00</updated>
    <id>blog.lilaiqun.com/15707746132238.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>转自 <a href="#">https://www.awaimai.com/509.html</a></p>
</blockquote>

<p>PHP说简单，但是要精通也不是一件简单的事。我们除了会使用之外，还得知道它底层的工作原理。</p>

<p>PHP是一种适用于web开发的动态语言。具体点说，就是<strong>一个用C语言实现包含大量组件的软件框架</strong>。更狭义点看，可以把它认为是一个强大的UI框架。</p>

<p>了解PHP底层实现的目的是什么？动态语言要像用好首先得了解它，内存管理、框架模型值得我们借鉴，通过扩展开发实现更多更强大的功能，优化我们程序的性能。</p>

<h2 id="toc_0">1.PHP的设计理念及特点</h2>

<ul>
<li><strong>多进程模型</strong>：由于PHP是多进程模型，不同请求间互不干涉，这样保证了一个请求挂掉不会对全盘服务造成影响。当然，随着时代发展，PHP也早已支持多线程模型。</li>
<li><strong>弱类型语言</strong>：和C/C++、Java、C#等语言不同，PHP是一门弱类型语言。一个变量的类型并不是一开始就确定不变，运行中才会确定并可能发生隐式或显式的类型转换，这种机制的灵活性在web开发中非常方便、高效，具体会在后面PHP变量中详述。</li>
<li><strong>引擎(Zend)+组件(ext)</strong>的模式降低内部耦合。</li>
<li><strong>中间层(sapi)</strong> 隔绝web server和PHP。</li>
<li><strong>语法简单灵活</strong>，没有太多规范。缺点导致风格混杂，但再差的程序员也不会写出太离谱危害全局的程序。</li>
</ul>

<h2 id="toc_1">2.PHP的四层体系</h2>

<p>PHP的核心架构如下图：</p>

<p><img src="media/15707746132238/15707748099010.jpg" alt=""/></p>

<p>从图上可以看出，PHP从下到上是一个4层体系：</p>

<ol>
<li><strong>Zend引擎</strong>：Zend整体用纯C实现，是PHP的内核部分，它将PHP代码翻译（词法、语法解析等一系列编译过程）为可执行opcode处理，并实现相应的处理方法，实现了基本的数据结构（如hashtable、oo）、内存分配及管理、提供了相应的api方法供外部调用，是一切的核心，所有的外围功能均围绕Zend实现。</li>
<li><strong>Extensions</strong>：围绕着Zend引擎，extensions通过组件式的方式提供各种基础服务，我们常见的各种内置函数（如array系列）、标准库等都是通过extension来实现，用户也可以根据需要实现自己的extension以达到功能扩展、性能优化等目的（如贴吧正在使用的PHP中间层、富文本解析就是extension的典型应用）。</li>
<li><strong>Sapi</strong>：Sapi全称是Server Application Programming Interface，也就是服务端应用编程接口，Sapi通过一系列钩子函数，使得PHP可以和外围交互数据，这是PHP非常优雅和成功的一个设计，通过sapi成功的将PHP本身和上层应用解耦隔离，PHP可以不再考虑如何针对不同应用进行兼容，而应用本身也可以针对自己的特点实现不同的处理方式。</li>
<li><strong>Application</strong>：这就是我们平时编写的PHP程序，通过不同的sapi方式得到各种各样的应用模式，如通过webserver实现web应用、在命令行下以脚本方式运行等等。  如果PHP是一辆车，那么车的框架就是PHP本身，Zend是车的引擎（发动机），Ext下面的各种组件就是车的轮子，Sapi可以看做是公路，车可以跑在不同类型的公路上，而一次PHP程序的执行就是汽车跑在公路上。因此，我们需要：性能优异的引擎+合适的车轮+正确的跑道。</li>
</ol>

<h2 id="toc_2">3.Sapi</h2>

<p>如前所述，Sapi通过通过一系列的接口，使得外部应用可以和PHP交换数据，并可以根据不同应用特点实现特定的处理方法，我们常见的一些sapi有：</p>

<ol>
<li><strong>apache2handler</strong>：这是以apache作为webserver，采用mod_PHP模式运行时候的处理方式。</li>
<li><strong>cgi</strong>：这是webserver和PHP直接的另一种交互方式，也就是大名鼎鼎的fastcgi协议，在最近今年fastcgi+PHP得到越来越多的应用，也是异步webserver所唯一支持的方式。</li>
<li><strong>cli</strong>：命令行调用的应用模式</li>
</ol>

<h2 id="toc_3">4.PHP的执行流程&amp;opcode</h2>

<p>我们先来看看PHP代码的执行所经过的流程。</p>

<p>从图上可以看到，PHP实现了一个典型的动态语言执行过程：拿到一段代码后，经过词法解析、语法解析等阶段后，源程序会被翻译成一个个指令(<code>opcodes</code>)，然后ZEND虚拟机顺次执行这些指令完成操作。PHP本身是用C实现的，因此最终调用的也都是C的函数，实际上，我们可以把PHP看做是一个C开发的软件。</p>

<p>PHP的执行的核心是翻译出来的一条一条指令，也即opcode。</p>

<p>Opcode是PHP程序执行的最基本单位。一个opcode由两个参数(op1,op2)、返回值和处理函数组成。PHP程序最终被翻译为一组opcode处理函数的顺序执行。</p>

<p>常见的几个处理函数：</p>

<pre><code class="language-c">ZEND_ASSIGN_SPEC_CV_CV_HANDLER : 变量分配 （$a=$b）

ZEND_DO_FCALL_BY_NAME_SPEC_HANDLER：函数调用

ZEND_CONCAT_SPEC_CV_CV_HANDLER：字符串拼接 $a.$b

ZEND_ADD_SPEC_CV_CONST_HANDLER: 加法运算 $a+2

ZEND_IS_EQUAL_SPEC_CV_CONST：判断相等 $a==1

ZEND_IS_IDENTICAL_SPEC_CV_CONST：判断相等 $a===1
</code></pre>

<h2 id="toc_4">5.HashTable — 核心数据结构</h2>

<p>HashTable是Zend的核心数据结构，在PHP里面几乎并用来实现所有常见功能，我们知道的PHP数组即是其典型应用，此外，在zend内部，如函数符号表、全局变量等也都是基于hash table来实现。</p>

<p>PHP的hash table具有如下特点：</p>

<ol>
<li>支持典型的key-&gt;value查询</li>
<li>可以当做数组使用</li>
<li>添加、删除节点是 O(1) 复杂度</li>
<li>key支持混合类型：同时存在关联数组合索引数组</li>
<li>Value支持混合类型：<code>array (&quot;string&quot;, 2332)</code></li>
<li>支持线性遍历：如foreach</li>
</ol>

<p>Zend hash table实现了典型的hash表散列结构，同时通过附加一个双向链表，提供了正向、反向遍历数组的功能。其结构如下图：</p>

<p><img src="media/15707746132238/15707754457694.jpg" alt=""/></p>

<p>可以看到，在hash table中既有key-&gt;value形式的散列结构，也有双向链表模式，使得它能够非常方便的支持快速查找和线性遍历。</p>

<p>散列结构：Zend的散列结构是典型的hash表模型，通过链表的方式来解决冲突。需要注意的是zend的hash table是一个自增长的数据结构，当hash表数目满了之后，其本身会动态以2倍的方式扩容并重新元素位置。初始大小均为8。另外，在进行key-&gt;value快速查找时候，zend本身还做了一些优化，通过空间换时间的方式加快速度。比如在每个元素中都会用一个变量nKeyLength标识key的长度以作快速判定。<br/>
双向链表：Zend hash table通过一个链表结构，实现了元素的线性遍历。理论上，做遍历使用单向链表就够了，之所以使用双向链表，主要目的是为了快速删除，避免遍历。Zend hash table是一种复合型的结构，作为数组使用时，即支持常见的关联数组也能够作为顺序索引数字来使用，甚至允许2者的混合。<br/>
PHP关联数组：关联数组是典型的hash_table应用。一次查询过程经过如下几步（从代码可以看出，这是一个常见的hash查询过程，并增加一些快速判定加速查找。）：<br/>
getKeyHashValue h;<br/>
index = n &amp; nTableMask;<br/>
Bucket *p = arBucket[index];<br/>
while (p) {<br/>
    if ((p-&gt;h == h) &amp; (p-&gt;nKeyLength == nKeyLength)) {<br/>
        RETURN p-&gt;data;<br/><br/>
    }<br/>
    p=p-&gt;next;<br/>
}<br/>
RETURN FALTURE;<br/>
PHP索引数组：索引数组就是我们常见的数组，通过下标访问。例如 \(arr[0]，Zend HashTable内部进行了归一化处理，对于index类型key同样分配了hash值和nKeyLength(为0)。内部成员变量nNextFreeElement就是当前分配到的最大id，每次push后自动加一。正是这种归一化处理，PHP才能够实现关联和非关联的混合。由于push操作的特殊性，索引key在PHP数组中先后顺序并不是通过下标大小来决定，而是由push的先后决定。例如 \)arr[1] = 2; $arr[2] = 3; 对于double类型的key，Zend HashTable会将他当做索引key处理</p>

<ol>
<li>PHP变量<br/>
PHP是一门弱类型语言，本身不严格区分变量的类型。PHP在变量申明的时候不需要指定类型。PHP在程序运行期间可能进行变量类型的隐示转换。和其他强类型语言一样，程序中也可以进行显示的类型转换。PHP变量可以分为简单类型(int、string、bool)、集合类型(array resource object)和常量(const)。以上所有的变量在底层都是同一种结构 zval。</li>
</ol>

<p>Zval是zend中另一个非常重要的数据结构，用来标识并实现PHP变量，其数据结构如下：</p>

<p>Zval主要由三部分组成：</p>

<p>type：指定了变量所述的类型（整数、字符串、数组等）<br/>
refcount&amp;is_ref：用来实现引用计数(后面具体介绍)<br/>
value：核心部分，存储了变量的实际数据<br/>
Zvalue是用来保存一个变量的实际数据。因为要存储多种类型，所以zvalue是一个union，也由此实现了弱类型。</p>

<p>PHP变量类型和其实际存储对应关系如下：</p>

<p>IS_LONG   -&gt; lvalue<br/>
IS_DOUBLE -&gt; dvalue<br/>
IS_ARRAY  -&gt; ht<br/>
IS_STRING -&gt; str<br/>
IS_RESOURCE -&gt; lvalue<br/>
引用计数<br/>
引用计数在内存回收、字符串操作等地方使用非常广泛。PHP中的变量就是引用计数的典型应用。Zval的引用计数通过成员变量is_ref和ref_count实现，通过引用计数，多个变量可以共享同一份数据。避免频繁拷贝带来的大量消耗。</p>

<p>在进行赋值操作时，zend将变量指向相同的zval同时ref_count++，在unset操作时，对应的ref_count-1。只有ref_count减为0时才会真正执行销毁操作。如果是引用赋值，则zend会修改is_ref为1。</p>

<p>PHP变量通过引用计数实现变量共享数据，那如果改变其中一个变量值呢？当试图写入一个变量时，Zend若发现该变量指向的zval被多个变量共享，则为其复制一份ref_count为1的zval，并递减原zval的refcount，这个过程称为“zval分离”。可见，只有在有写操作发生时zend才进行拷贝操作，因此也叫copy-on-write(写时拷贝)</p>

<p>对于引用型变量，其要求和非引用型相反，引用赋值的变量间必须是捆绑的，修改一个变量就修改了所有捆绑变量。</p>

<p>整数和浮点数<br/>
整数、浮点数是PHP中的基础类型之一，也是一个简单型变量。对于整数和浮点数，在zvalue中直接存储对应的值。其类型分别是long和double。</p>

<p>从zvalue结构中可以看出，对于整数类型，和c等强类型语言不同，PHP是不区分int、unsigned int、long、long long等类型的，对它来说，整数只有一种类型也就是long。由此，可以看出，在PHP里面，整数的取值范围是由编译器位数来决定而不是固定不变的。</p>

<p>对于浮点数，类似整数，它也不区分float和double而是统一只有double一种类型。</p>

<p>在PHP中，如果整数范围越界了怎么办？这种情况下会自动转换为double类型，这个一定要小心，很多trick都是由此产生。</p>

<p>字符和字符串<br/>
和整数一样，字符变量也是PHP中的基础类型和简单型变量。通过zvalue结构可以看出，在PHP中，字符串是由由指向实际数据的指针和长度结构体组成，这点和c++中的string比较类似。由于通过一个实际变量表示长度，和c不同，它的字符串可以是2进制数据（包含\0），同时在PHP中，求字符串长度strlen是O(1)操作。</p>

<p>在新增、修改、追加字符串操作时，PHP都会重新分配内存生成新的字符串。最后，出于安全考虑，PHP在生成一个字符串时末尾仍然会添加\0。</p>

<p>常见的字符串拼接方式及速度比较：</p>

<p>假设有如下4个变量：</p>

<p>\(strA = &#39;123&#39;;<br/>
\)strB = &#39;456&#39;;<br/>
\(intA = 123;<br/>
\)intB = 456;<br/>
现在对如下的几种字符串拼接方式做一个比较和说明：</p>

<p>// 下面两张情况，zend会重新malloc一块内存并进行相应处理，其速度一般<br/>
\(res = \)strA . \(strB<br/>
\)res = &quot;\(strA\)strB&quot;</p>

<p>// 这种是速度最快的，zend会在当前strA基础上直接relloc，避免重复拷贝<br/>
\(strA = \)strA . $strB</p>

<p>// 这种速度较慢，因为需要做隐式的格式转换，实际编写程序中也应该注意尽量避免<br/>
\(res = \)intA . $intB</p>

<p>// 这会是最慢的一种方式，因为sprintf在PHP中并不是一个语言结构，<br/>
// 本身对于格式识别和处理就需要耗费比较多时间，另外本身机制也是malloc。<br/>
// 不过sprintf的方式最具可读性，实际中可以根据具体情况灵活选择。<br/>
\(strA = sprintf (&quot;%s%s&quot;, \)strA . $strB);<br/>
数组<br/>
PHP的数组通过Zend HashTable来天然实现。</p>

<p>foreach操作如何实现？对一个数组的foreach就是通过遍历hashtable中的双向链表完成。对于索引数组，通过foreach遍历效率比for高很多，省去了key-&gt;value的查找。count操作直接调用HashTable-&gt;NumOfElements，O(1)操作。对于 &#39;123&#39; 这样的字符串，zend会转换为其整数形式。\(arr[&#39;123&#39;]和\)arr[123]是等价的。</p>

<p>资源<br/>
资源类型变量是PHP中最复杂的一种变量，也是一种复合型结构。</p>

<p>PHP的zval可以表示广泛的数据类型，但是对于自定义的数据类型却很难充分描述。由于没有有效的方式描绘这些复合结构，因此也没有办法对它们使用传统的操作符。要解决这个问题，只需要通过一个本质上任意的标识符（label）引用指针，这种方式被称为资源。</p>

<p>在zval中，对于resource，lval作为指针来使用，直接指向资源所在的地址。Resource可以是任意的复合结构，我们熟悉的mysqli、fsock、memcached等都是资源。</p>

<p>如何使用资源：</p>

<p>注册：对于一个自定义的数据类型，要想将它作为资源。首先需要进行注册，zend会为它分配全局唯一标示。<br/>
获取一个资源变量：对于资源，zend维护了一个id-&gt;实际数据的hash_tale。对于一个resource，在zval中只记录了它的id。fetch的时候通过id在hash_table中找到具体的值返回。<br/>
资源销毁：资源的数据类型是多种多样的。Zend本身没有办法销毁它。因此需要用户在注册资源的时候提供销毁函数。当unset资源时，zend调用相应的函数完成析构。同时从全局资源表中删除它。<br/>
资源可以长期驻留，不只是在所有引用它的变量超出作用域之后，甚至是在一个请求结束了并且新的请求产生之后。这些资源称为持久资源，因为它们贯通SAPI的整个生命周期持续存在，除非特意销毁。很多情况下，持久化资源可以在一定程度上提高性能。比如我们常见的mysql_pconnect ,持久化资源通过pemalloc分配内存，这样在请求结束的时候不会释放。 对zend来说，对两者本身并不区分。</p>

<p>变量作用域<br/>
PHP中的局部变量和全局变量是如何实现的？对于一个请求，任意时刻PHP都可以看到两个符号表(symbol_table和active_symbol_table)，其中前者用来维护全局变量。后者是一个指针，指向当前活动的变量符号表，当程序进入到某个函数中时，zend就会为它分配一个符号表x同时将active_symbol_table指向a。通过这样的方式实现全局、局部变量的区分。</p>

<p>获取变量值：PHP的符号表是通过hash_table实现的，对于每个变量都分配唯一标识，获取的时候根据标识从表中找到相应zval返回。</p>

<p>函数中使用全局变量：在函数中，我们可以通过显式申明global来使用全局变量。在active_symbol_table中创建symbol_table中同名变量的引用，如果symbol_table中没有同名变量则会先创建。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何练好SQL]]></title>
    <link href="blog.lilaiqun.com/15706131641039.html"/>
    <updated>2019-10-09T17:26:04+08:00</updated>
    <id>blog.lilaiqun.com/15706131641039.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>摘自 <a href="#">https://www.cnblogs.com/xiaoyangjia/p/11267191.html</a></p>
</blockquote>

<p>博主负责的项目主要采用阿里云数据库MySQL，最近频繁出现慢SQL告警，执行时间最长的竟然高达5分钟。导出日志后分析，主要原因竟然是<strong>没有命中索引</strong>和<strong>没有分页处理</strong>。其实这是非常低级的错误，我不禁后背一凉，团队成员的技术水平亟待提高啊。改造这些SQL的过程中，总结了一些经验分享给大家，如果有错误欢迎批评指正。</p>

<h2 id="toc_0">1.MySQL性能</h2>

<h3 id="toc_1">1.1.最大数据量</h3>

<p>  抛开数据量和并发数，谈性能都是耍流氓。MySQL没有限制单表最大记录数，它取决于操作系统对文件大小的限制。</p>

<table>
<thead>
<tr>
<th>文件系统</th>
<th>单文件大小限制</th>
</tr>
</thead>

<tbody>
<tr>
<td>FAT32</td>
<td>最大4G</td>
</tr>
<tr>
<td>NTFS</td>
<td>最大64GB</td>
</tr>
<tr>
<td>NTFS5.0</td>
<td>最大2TB</td>
</tr>
<tr>
<td>EXT2</td>
<td>块大小为1024字节，文件最大容量16GB；块大小为4096字节，文件最大容量2TB</td>
</tr>
<tr>
<td>EXT3</td>
<td>块大小为4KB，文件最大容量为4TB</td>
</tr>
<tr>
<td>EXT4</td>
<td>理论可以大于16TB</td>
</tr>
</tbody>
</table>

<p>《阿里巴巴Java开发手册》提出单表行数超过500万行或者单表容量超过2GB，才推荐分库分表。性能由综合因素决定，抛开业务复杂度，影响程度依次是硬件配置、MySQL配置、数据表设计、索引优化。500万这个值仅供参考，并非铁律。博主曾经操作过超过4亿行数据的单表，分页查询最新的20条记录耗时0.6秒，SQL语句大致是<code>select field_1,field_2 from table where id &lt; #{prePageMinId} order by id desc limit 20，prePageMinId</code> 是上一页数据记录的最小ID。虽然当时查询速度还凑合，随着数据不断增长，有朝一日必定不堪重负。分库分表是个周期长而风险高的大活儿，应该尽可能在当前结构上优化，比如升级硬件、迁移历史数据等等，实在没辙了再分。对分库分表感兴趣的同学可以阅读分库分表的基本思想。</p>

<h3 id="toc_2">1.2.最大并发数</h3>

<p>  并发数是指同一时刻数据库能处理多少个请求，由<code>max_connections</code>和<code>max_user_connections</code>决定。<code>max_connections</code>是指MySQL实例的最大连接数，上限值是16384，<code>max_user_connections</code>是指每个数据库用户的最大连接数。MySQL会为每个连接提供缓冲区，意味着消耗更多的内存。如果连接数设置太高硬件吃不消，太低又不能充分利用硬件。一般要求两者比值超过10%，计算方法如下：<br/>
<code>max_used_connections / max_connections * 100% = 3/100 *100% ≈ 3%</code></p>

<p>查看最大连接数与响应最大连接数：</p>

<pre><code class="language-text">show variables like &#39;%max_connections%&#39;;
show variables like &#39;%max_user_connections%&#39;;
</code></pre>

<p>在配置文件<code>my.cnf</code>中修改最大连接数</p>

<pre><code class="language-text">[mysqld]
max_connections = 100
max_used_connections = 20
</code></pre>

<h3 id="toc_3">1.3.查询耗时0.5秒</h3>

<p>  建议将单次查询耗时控制在0.5秒以内，0.5秒是个经验值，源于用户体验的3秒原则。如果用户的操作3秒内没有响应，将会厌烦甚至退出。响应时间=客户端UI渲染耗时+网络请求耗时+应用程序处理耗时+查询数据库耗时，0.5秒就是留给数据库1/6的处理时间。</p>

<h3 id="toc_4">1.4.实施原则</h3>

<p>  相比NoSQL数据库，MySQL是个娇气脆弱的家伙。它就像体育课上的女同学，一点纠纷就和同学闹别扭(扩容难)，跑两步就气喘吁吁(容量小并发低)，常常身体不适要请假(SQL约束太多)。如今大家都会搞点分布式，应用程序扩容比数据库要容易得多，所以实施原则是数据库少干活，应用程序多干活。</p>

<ul>
<li>充分利用但不滥用索引，须知索引也消耗磁盘和CPU。</li>
<li>不推荐使用数据库函数格式化数据，交给应用程序处理。</li>
<li>不推荐使用外键约束，用应用程序保证数据准确性。</li>
<li>写多读少的场景，不推荐使用唯一索引，用应用程序保证唯一性。</li>
<li>适当冗余字段，尝试创建中间表，用应用程序计算中间结果，用空间换时间。</li>
<li>不允许执行极度耗时的事务，配合应用程序拆分成更小的事务。</li>
<li>预估重要数据表（比如订单表）的负载和数据增长态势，提前优化。</li>
</ul>

<h2 id="toc_5">2.数据表设计</h2>

<h3 id="toc_6">2.1.数据类型</h3>

<p>  数据类型的选择原则：更简单或者占用空间更小。</p>

<ul>
<li>如果长度能够满足，整型尽量使用<code>tinyint</code>、<code>smallint</code>、<code>medium_int</code>而非<code>int</code>。</li>
<li>如果字符串长度确定，采用<code>char</code>类型。</li>
<li>如果<code>varchar</code>能够满足，不采用<code>text</code>类型。</li>
<li>精度要求较高的使用<code>decimal</code>类型，也可以使用<code>BIGINT</code>，比如精确两位小数就乘以100后保存。</li>
<li>尽量采用<code>timestamp</code>而非<code>datetime</code>。</li>
</ul>

<table>
<thead>
<tr>
<th>类型</th>
<th>占据字节</th>
<th>描述</th>
</tr>
</thead>

<tbody>
<tr>
<td>datetime</td>
<td><strong>8字节</strong></td>
<td>&#39;1000-01-01 00:00:00.000000&#39; to &#39;9999-12-31 23:59:59.999999</td>
</tr>
<tr>
<td>timestamp</td>
<td><strong>4字节</strong></td>
<td>&#39;1970-01-01 00:00:01.000000&#39; to &#39;2038-01-19 03:14:07.999999&#39;</td>
</tr>
</tbody>
</table>

<p>相比datetime，timestamp占用更少的空间，以UTC的格式储存自动转换时区。</p>

<h3 id="toc_7">2.2.避免空值</h3>

<p>  MySQL中字段为<code>NULL</code>时依然占用空间，会使索引、索引统计更加复杂。从<code>NULL</code>值更新到非NULL无法做到原地更新，容易发生索引分裂影响性能。尽可能将NULL值用有意义的值代替，也能避免SQL语句里面包含<code>is not null</code>的判断。</p>

<h3 id="toc_8">2.3.text类型优化</h3>

<p>  由于text字段储存大量数据，表容量会很早涨上去，影响其他字段的查询性能。建议抽取出来放在子表里，用业务主键关联。</p>

<h2 id="toc_9">3.索引优化</h2>

<h3 id="toc_10">3.1.索引分类</h3>

<ol>
<li><strong>普通索引</strong>：最基本的索引。</li>
<li><strong>组合索引</strong>：多个字段上建立的索引，能够加速复合查询条件的检索。</li>
<li><strong>唯一索引</strong>：与普通索引类似，但索引列的值必须唯一，允许有空值。</li>
<li><strong>组合唯一索引</strong>：列值的组合必须唯一。</li>
<li><strong>主键索引</strong>：特殊的唯一索引，用于唯一标识数据表中的某一条记录，不允许有空值，一般用primary key约束。</li>
<li><strong>全文索引</strong>：用于海量文本的查询，MySQL5.6之后的InnoDB和MyISAM均支持全文索引。由于查询精度以及扩展性不佳，更多的企业选择Elasticsearch。</li>
</ol>

<h3 id="toc_11">3.2.索引优化</h3>

<p>分页查询很重要，如果查询数据量超过30%，MYSQL不会使用索引。<br/>
单表索引数不超过5个、单个索引字段数不超过5个。<br/>
字符串可使用前缀索引，前缀长度控制在5-8个字符。<br/>
字段唯一性太低，增加索引没有意义，如：是否删除、性别。<br/>
合理使用覆盖索引，如下所示：<br/>
<code>select login_name, nick_name from member where login_name = ?</code><br/>
<code>login_name, nick_name</code>两个字段建立组合索引，比<code>login_name</code>简单索引要更快</p>

<h2 id="toc_12">4.SQL优化</h2>

<h3 id="toc_13">4.1.分批处理</h3>

<p>  博主小时候看到鱼塘挖开小口子放水，水面有各种漂浮物。浮萍和树叶总能顺利通过出水口，而树枝会挡住其他物体通过，有时还会卡住，需要人工清理。MySQL就是鱼塘，最大并发数和网络带宽就是出水口，用户SQL就是漂浮物。不带分页参数的查询或者影响大量数据的update和delete操作，都是树枝，我们要把它打散分批处理，举例说明：<br/>
业务描述：更新用户所有已过期的优惠券为不可用状态。<br/>
SQL语句：</p>

<pre><code class="language-sql">UPDATE status=0 FROM `coupon` WHERE expire_date &lt;= #{currentDate} and status=1;
</code></pre>

<p>如果大量优惠券需要更新为不可用状态，执行这条SQL可能会堵死其他SQL，分批处理伪代码如下：</p>

<pre><code class="language-sql">int pageNo = 1;
int PAGE_SIZE = 100;
while(true) {
    List&lt;Integer&gt; batchIdList = queryList(&#39;select id FROM `coupon` WHERE expire_date &lt;= #{currentDate} and status = 1 limit #{(pageNo-1) * PAGE_SIZE},#{PAGE_SIZE}&#39;);
    if (CollectionUtils.isEmpty(batchIdList)) {
        return;
    }
    update(&#39;update status = 0 FROM `coupon` WHERE status = 1 and id in #{batchIdList}&#39;)
    pageNo ++;
}
</code></pre>

<h3 id="toc_14">4.2.操作符&lt;&gt;优化</h3>

<p>  通常&lt;&gt;操作符无法使用索引，举例如下，查询金额不为100元的订单：</p>

<pre><code class="language-sql">SELECT id FROM orders WHERE amount != 100;
</code></pre>

<p>如果金额为100的订单极少，这种数据分布严重不均的情况下，有可能使用索引。鉴于这种不确定性，采用union聚合搜索结果，改写方法如下：</p>

<pre><code class="language-sql">(SELECT id FROM orders WHERE amount &gt; 100)
 union all
(SELECT id FROM orders WHERE amount &lt; 100 and amount &gt; 0)
</code></pre>

<h3 id="toc_15">4.3.OR优化</h3>

<p>  在Innodb引擎下or无法使用组合索引，比如：</p>

<pre><code class="language-sql">SELECT id，product_name FROM orders WHERE mobile_no = &#39;13421800407&#39; or user_id = 100;
</code></pre>

<p>OR无法命中mobile_no + user_id的组合索引，可采用union，如下所示：</p>

<pre><code class="language-sql">(SELECT id，product_name FROM orders WHERE mobile_no = &#39;13421800407&#39;)
 union
(SELECT id，product_name FROM orders WHERE user_id = 100);
</code></pre>

<p>此时id和product_name字段都有索引，查询才最高效。</p>

<h3 id="toc_16">4.4.IN优化</h3>

<p>IN适合主表大子表小，EXIST适合主表小子表大。由于查询优化器的不断升级，很多场景这两者性能差不多一样了。<br/>
尝试改为join查询，举例如下：</p>

<pre><code class="language-sql">SELECT id FROM orders WHERE user_id IN (SELECT id FROM user WHERE level = &#39;VIP&#39;);
</code></pre>

<p>采用JOIN如下所示：</p>

<pre><code class="language-sql">SELECT o.id FROM orders o LEFT JOIN user u ON o.user_id = u.id WHERE u.level = &#39;VIP&#39;;
</code></pre>

<h3 id="toc_17">4.5.不做列运算</h3>

<p>  通常在查询条件列运算会导致索引失效，如下所示：<br/>
查询当日订单</p>

<pre><code class="language-sql">SELECT id FROM order WHERE date_format(create_time，&#39;%Y-%m-%d&#39;) = &#39;2019-07-01&#39;;
</code></pre>

<p>date_format函数会导致这个查询无法使用索引，改写后：</p>

<pre><code class="language-sql">SELECT id FROM order WHERE create_time BETWEEN &#39;2019-07-01 00:00:00&#39; AND &#39;2019-07-01 23:59:59&#39;;
</code></pre>

<h3 id="toc_18">4.6.避免Select all</h3>

<p>  如果不查询表中所有的列，避免使用SELECT *，它会进行全表扫描，不能有效利用索引。</p>

<h3 id="toc_19">4.7.Like优化</h3>

<p>  like用于模糊查询，举个例子（field已建立索引）：</p>

<pre><code class="language-sql">SELECT column FROM table WHERE field like &#39;%keyword%&#39;;
</code></pre>

<p>这个查询未命中索引，换成下面的写法：</p>

<pre><code class="language-sql">SELECT column FROM table WHERE field like &#39;keyword%&#39;;
</code></pre>

<p>去除了前面的%查询将会命中索引，但是产品经理一定要前后模糊匹配呢？全文索引fulltext可以尝试一下，但Elasticsearch才是终极武器。</p>

<h3 id="toc_20">4.8.Join优化</h3>

<p>  join的实现是采用Nested Loop Join算法，就是通过驱动表的结果集作为基础数据，通过该结数据作为过滤条件到下一个表中循环查询数据，然后合并结果。如果有多个join，则将前面的结果集作为循环数据，再次到后一个表中查询数据。</p>

<p>驱动表和被驱动表尽可能增加查询条件，满足ON的条件而少用Where，用小结果集驱动大结果集。<br/>
被驱动表的join字段上加上索引，无法建立索引的时候，设置足够的Join Buffer Size。<br/>
禁止join连接三个以上的表，尝试增加冗余字段。</p>

<h3 id="toc_21">4.9.Limit优化</h3>

<p>  limit用于分页查询时越往后翻性能越差，解决的原则：缩小扫描范围，如下所示：</p>

<pre><code class="language-sql">SELECT * FROM orders ORDER BY id DESC LIMIT 100000,10 
</code></pre>

<p>耗时0.4秒</p>

<pre><code class="language-sql">SELECT * FROM orders ORDER BY id DESC LIMIT 1000000,10
</code></pre>

<p>耗时5.2秒<br/>
先筛选出ID缩小查询范围，写法如下：</p>

<pre><code class="language-sql">SELECT * FROM orders WHERE id &gt; (SELECT id FROM orders ORDER BY id DESC LIMIT 1000000, 1) ORDER BY id DESC LIMIT 0,10
</code></pre>

<p>耗时0.5秒<br/>
如果查询条件仅有主键ID，写法如下：</p>

<pre><code class="language-sql">SELECT id FROM orders WHERE id BETWEEN 1000000 AND 1000010 ORDER BY id DESC
</code></pre>

<p>耗时0.3秒<br/>
如果以上方案依然很慢呢？只好用游标了，感兴趣的朋友阅读JDBC使用游标实现分页查询的方法</p>

<h2 id="toc_22">5.其他数据库</h2>

<p>  作为一名后端开发人员，务必精通作为存储核心的MySQL或SQL Server，也要积极关注NoSQL数据库，他们已经足够成熟并被广泛采用，能解决特定场景下的性能瓶颈。</p>

<table>
<thead>
<tr>
<th>分类</th>
<th>数据库</th>
<th>特性</th>
</tr>
</thead>

<tbody>
<tr>
<td>键值型</td>
<td>Memcache</td>
<td>用于内容缓存，大量数据的高访问负载</td>
</tr>
<tr>
<td>键值型</td>
<td>Redis</td>
<td>用于内容缓存，比Memcache支持更多的数据类型，并能持久化数据</td>
</tr>
<tr>
<td>列式存储</td>
<td>HBase</td>
<td>Hadoop体系的核心数据库，海量结构化数据存储，大数据必备。</td>
</tr>
<tr>
<td>文档型</td>
<td>MongoDb</td>
<td>知名文档型数据库，也可以用于缓存</td>
</tr>
<tr>
<td>文档型</td>
<td>CouchDB</td>
<td>Apache的开源项目，专注于易用性，支持REST API</td>
</tr>
<tr>
<td>文档型</td>
<td>SequoiaDB</td>
<td>国内知名文档型数据库</td>
</tr>
<tr>
<td>图形</td>
<td>Neo4J</td>
<td>图形    Neo4J   用于社交网络构建关系图谱，推荐系统等</td>
</tr>
</tbody>
</table>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[遭遇php的in_array低性能]]></title>
    <link href="blog.lilaiqun.com/15706006250325.html"/>
    <updated>2019-10-09T13:57:05+08:00</updated>
    <id>blog.lilaiqun.com/15706006250325.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>转自： <a href="#">https://www.zendstudio.net/archives/php-in_array-s-low-performance/</a></p>
</blockquote>

<pre><code class="language-php">&lt;?php
$y = &quot;1800&quot;;
$x = array();
for($j=0;$j&lt;2000;$j++){
    $x[]= &quot;{$j}&quot;;
}
for($i=0;$i&lt;3000;$i++){
    if(in_array($y,$x)){
            continue;
    }
}
</code></pre>

<p>执行：</p>

<pre><code class="language-text">$ time php test.php

real    0m0.986s
user    0m0.381s
sys 0m0.016s
</code></pre>

<p>对的，我们用的就是字符串型的数字，从缓存拿出来就是这样子的啦！所以这里是特意转成字符串的（如果直接是数字，并不会出现这个问题 ，各位可以自行验证）。可以看出时间耗掉了1秒，才3000次循环,后面的sys用时也注定我们用strace不会拿到什么有效信息。</p>

<pre><code class="language-bash">$ strace -ttt -o xxx php test.php
$ less xxx


</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[zval定义]]></title>
    <link href="blog.lilaiqun.com/15705095538983.html"/>
    <updated>2019-10-08T12:39:13+08:00</updated>
    <id>blog.lilaiqun.com/15705095538983.html</id>
    <content type="html"><![CDATA[
<p>zval可以表示一切PHP中的数据类型, 所以它包含了一个<code>type</code>字段, 表示这个zval存储的是什么类型的值, 常见的可能选项是<code>IS_NULL</code>, <code>IS_LONG</code>, <code>IS_STRING</code>, <code>IS_ARRAY</code>, <code>IS_OBJECT</code>等等.</p>

<pre><code class="language-c"># 文件 zend_types.h
struct _zval_struct {
    zend_value value;   // 8字节
    union u1;           // 4字节
    union u2;           // 4字节
}

# u1
union {
    struct {
        ZEND_ENDIAN_LOHI_4(
            zend_uchar type,    // type就是下面的17种类型
            zend_uchar type_flags,
            zend_uchar const_flags,
            zend_uchar reserved
        )
    } v;
    uint32_t type_info;
} u1;

# u2
union {
    uint32_t next;              // hash collision chain
    uint32_t cache_slot;        //literal cache slot
    uint32_t lineno;            // line number (for ast nodes)
    uint32_t fe_pos;            // foreach position
    uint32_t fe_iter_idx;       // foreach iterator index
    uint32_t access_flags;      // class constant access flags
    uint32_t property_guard;    // single property guard
} u2;

typedef union _zend_value {
    zend_long lval;
    double dval;
    zend_refcounted *counted;
    zend_string *str;
    zend_array *arr;
    zend_object *obj;
    zend_resource *res;
    zend_reference *ref;
    zend_ast_ref *ast;
    zval *zv;
    void *ptr;
    zend_class_entry *ce;
    zend_function *func;
} zend_value;
</code></pre>

<h2 id="toc_0">如何确定变量的类型</h2>

<p>PHP7中的zval的类型做了比较大的调整, 总体来说有如下17种类型:</p>

<pre><code class="language-c">/* regular data types */
#define IS_UNDEF                    0
#define IS_NULL                     1
#define IS_FALSE                    2
#define IS_TRUE                     3
#define IS_LONG                     4
#define IS_DOUBLE                   5
#define IS_STRING                   6
#define IS_ARRAY                    7
#define IS_OBJECT                   8
#define IS_RESOURCE                 9
#define IS_REFERENCE                10
 
/* constant expressions */
#define IS_CONSTANT                 11
#define IS_CONSTANT_AST             12
 
/* fake types */
#define _IS_BOOL                    13
#define IS_CALLABLE                 14
 
/* internal types */
#define IS_INDIRECT                 15
#define IS_PTR                      17
</code></pre>

<h2 id="toc_1">php7中赋值</h2>

<p>1.普通赋值  </p>

<p>在php中，定义一个变量<code>$a=&quot;444&quot;</code>，实际上是生成了一个<code>zval</code>，和一个<code>zend_value</code>,然后<code>zval</code>指向这个<code>zend_value</code>来实现对<code>$a=&quot;444&quot;</code>的定义的，然后通过<code>refcount</code>来统计引用的次数。</p>

<p>refcount表示当前有多少个zval指向同一个zend_value</p>

<p>像<code>bool</code>型还有<code>int</code>，<code>double</code>，<code>null</code>变量，他们的直接通过<code>zval</code>保存，不会公用一个<code>zend_value</code>,所以直接使用深拷贝。<br/>
至于什么是深拷贝，什么是浅拷贝，最直接的区别就是在于<strong>有没有重新生成一个一模一样的zend_value</strong>，详细请参看深拷贝和浅拷贝。</p>

<p>2.引用赋值</p>

<p>php中的引用赋值就是我们常用的引用，例如<code>$a=&amp;$b</code></p>

<p><img src="http://images.lilaiqun.com/15705125876412.jpg" alt=""/></p>

<h2 id="toc_2">查看zval</h2>

<pre><code class="language-php">&lt;?php
$a = 2;
echo $a;
$b = 1.1;
echo $b;
$c = null;
echo $c;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[5分钟商学院]]></title>
    <link href="blog.lilaiqun.com/15704615997009.html"/>
    <updated>2019-10-07T23:19:59+08:00</updated>
    <id>blog.lilaiqun.com/15704615997009.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">概念：信息对称</h2>

<p>所谓信息对称，就是说，在市场条件下，想实现有效的交易，交易双方掌握的信息必须对称，信息如果不对称，掌握信息比较充分的人员，往往会处于比较有利的地位。</p>

<p><strong>运用：场景</strong></p>

<ul>
<li>新创品牌如何获得市场认可？</li>
</ul>

<p>你是一个新创品牌，你做的商品的品质并不 比大牌差，你做的产品卖500块，那些大牌 贴上标签就要卖1000块，这500到1000之间的差价，我们称之为叫品牌溢价。很多人 愿意买大品牌1000块的，是因为宁愿多花 500块也要买一个品质有保障的。<br/>
互联网赋予了你—个可以挑战大品牌的机 会，你只需要选择一个有用户评价的体系， 比如大众点评，比如支付宝，如果你的商品真的很好的话，一个没有品牌的好产品，将有可能迅速战胜一个有品牌的平庸之作。</p>

<p><strong>小结：怎么解决信息不对称的问题？</strong></p>

<p>过去，我们通过品牌连锁经营和担保交易等 等—系列的手段，来解决这个不对称的问 题，但是今天的互联网，给我们提供了—个 全新、高效率地让信息对称的手段，让创造 这些手段的互联网公司，以及善于利用这些 手段的好产品，有机会以小胜大、获得消费 者的认可。信息对称是互联网改变商业世界 的底层逻辑。</p>

<h2 id="toc_1">概念：网络效应</h2>

<p>某种产品对一名用户的价值，取决于使用这 个产品的其他用户的数量，在经济学中，我 们把它称之为：网络效应。用户越多，越有 价值；越有价值，用户越多；不断地积累用 户的黏性。甚至，一旦用户总数突破一个临 界点之后，会最终进入“赢家通吃”的状 态。正如著名的投资人克里斯-迪克森所 说：为工具而来，为网络而留。</p>

<p>微信，使用的人越多，对你就越有价值， 当好友数量达到一定程度时，你们之间就 形成了一张错综复杂的网络。就算有一 天，你打算从微信换到另一个更好用的社 交软件上，也很有可能因为大部分朋友都 在微信上，而不得不回来。</p>

<h2 id="toc_2">概念：边际成本</h2>

<p>边际成本值的是每多生产或者每多卖一件产品，所带来的总成本的增加。边际成本的结构性改变，是互联网经济对传统经济最重要的一个冲击。</p>

<p><strong>案例</strong></p>

<p><strong>苏宁 VS 京东</strong><br/>
苏宁门店只能服务20公里的用户，服务20公里外的用户需要再开家店。边际成本一定不为0，所以单店是否盈利非常重要。<br/>
京东商城前期投入巨大，但互联网能覆盖的用户数，理论上是无上限的，所以边际成本不断递减，最终接近于0.</p>

<p>制造业无法像虚拟产品将边际成本将为0，许多产品的趋势逐步变成：实体产品+虚拟服务。比如电视+媒体库，电话机+话费，用降低实体产品的价格方式，促进虚拟服务达到趋近于0的边际成本。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[数据库缓存]]></title>
    <link href="blog.lilaiqun.com/15701558070255.html"/>
    <updated>2019-10-04T10:23:27+08:00</updated>
    <id>blog.lilaiqun.com/15701558070255.html</id>
    <content type="html"><![CDATA[
<p>缓存数据是为了很少或不访问数据库服务器，高并发下，最大程度降低对数据服务器压力。</p>

<h2 id="toc_0">启用Mysql查询缓存</h2>

<pre><code class="language-text">query_cache_type
0: 不使用查询缓存
1：始终使用查询缓存
2：按需使用查询缓存

// 不使用
select SQL_NO_CACHE * from my_table;
// 使用
select SQL_CACHE * from my_table;
// 缓存大小
SET GLOBAL query_cache_size = 133333;
// 查看缓存命中次数
SHOW STATUS LIKE &#39;Qcache_hits&#39;

FLUSH QUERY CACHE;
RESET QUERY CACHE;
FLUSH TABLES;
</code></pre>

<table>
<thead>
<tr>
<th></th>
<th>Memcache</th>
<th>Redis</th>
</tr>
</thead>

<tbody>
<tr>
<td></td>
<td></td>
<td>依靠客户端来实现分布式读写</td>
</tr>
<tr>
<td>持久化</td>
<td>不支持</td>
<td>快照、AOF</td>
</tr>
</tbody>
</table>

<h2 id="toc_1">MySQL数据库层的优化</h2>

<p>优化方向： 数据表数据类型优化、索引优化、SQL语句优化、存储引擎的优化、数据表结构设计的优化、数据库服务器架构的优化</p>

<h3 id="toc_2">数据表数据类型优化</h3>

<p>字段使用什么数据类型 <br/>
tinyint smallint bigint<br/>
char varchar</p>

<h2 id="toc_3">索引的优化</h2>

<p>索引创建原则： 不是越多越好，复合索引的前缀原则，全表扫描优化，</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[动态语言的并发处理]]></title>
    <link href="blog.lilaiqun.com/15701061350831.html"/>
    <updated>2019-10-03T20:35:35+08:00</updated>
    <id>blog.lilaiqun.com/15701061350831.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>什么是进程、线程、协程<br/>
什么事多进程、多线程<br/>
同步阻塞模型<br/>
异步非阻塞模型</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">进程的3态模型： 进程在处理器上交替运行，状态在不断发生变化。</h2>

<ul>
<li>运行：进程的数目小于处理器的数目</li>
<li>就绪：进程获取除处理器外一切所需资源。就绪进程可以按多个优先级来划分队列。当进程由于时间片用完进入就绪状态，排入低优先级队列；当进程由I/O操作完成而进入就绪状态时，排入高优先级队列。</li>
<li>阻塞： 等待或睡眠状态，一个进程正在等待某个时间发生（请求IO并等待IO完成）而暂停运行，这是即使把处理器分配给进程也无法运行，故称该进程处于阻塞状态。</li>
</ul>

<h2 id="toc_1">线程的5态模型：</h2>

<ul>
<li>新建态： 刚刚被创建没被提交的状态，等待系统完成创建进程的所有必要信息。</li>
<li>活跃就绪： 进程在主存并可被调度的状态</li>
<li>终止态：进程已结束运行，回收除进程控制块外的其他资源，并让其他进程从进程控制块中收集有关信息</li>
<li>静止就绪：进程被换到辅存时的就绪状态，是不能被直接调度的状态，只有主存中没有活跃就绪态进程，或者是挂起就绪态进程具有更高的优先级，系统将把挂起就绪态进程调回主存并转换为活跃就绪。</li>
<li>活跃阻塞： 进程已在主存，一旦等待时间产生便进入活跃就绪状态。</li>
</ul>

<p>协程是一种用户态的轻量级线程，协程的调度完全由用户控制。协程拥有自己的寄存器上下文和栈。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器的上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文切换非常快。</p>

<h2 id="toc_2">线程与进程的区别</h2>

<ol>
<li>线程是进程的一个执行单元，进程内至少有一个线程，他们共享进程的地址空间，而进程由自己的独立的地址空间。</li>
<li>进程是资源分配和拥有的单位，同一个进程内的线程共享进程的资源。</li>
<li>线程是处理器调度的基本单位，进程不是</li>
<li>两者均可并发执行</li>
</ol>

<h2 id="toc_3">异步非阻塞</h2>

<p>Reactor有4个核心的操作</p>

<ol>
<li>add添加socket监听到reactor</li>
<li>set修改事件监听，可以设置监听的类型，如可读、可写</li>
<li>del从reactor中移除，不再监听事件</li>
<li>callback 事件发生后对应的处理逻辑，一般在add/set时制定</li>
</ol>

<p>Nginx：多线程Reactor<br/>
Swoole：多线程Reactor + 多进程Worker</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[页面静态化]]></title>
    <link href="blog.lilaiqun.com/15701041292991.html"/>
    <updated>2019-10-03T20:02:09+08:00</updated>
    <id>blog.lilaiqun.com/15701041292991.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">模板引擎Smarty</h2>

<h2 id="toc_1">ob系列函数</h2>

<p>ob_start()<br/>
ob_get_contents()<br/>
ob_clean()<br/>
ob_end_flush()</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[浏览器缓存和数据压缩]]></title>
    <link href="blog.lilaiqun.com/15701010542234.html"/>
    <updated>2019-10-03T19:10:54+08:00</updated>
    <id>blog.lilaiqun.com/15701010542234.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">HTTP缓存机制</h2>

<span id="more"></span><!-- more -->

<p>缓存分类，HTTP缓存模型中，如果请求成功会有3中情况：</p>

<ul>
<li>200 from cache： 直接从本地缓存中响应，没有向服务器发送请求</li>
<li>304 Not Modified: 协商缓存，请求头中发送一定的校验数据到服务器，如果服务器数据没有改变浏览器从本地缓存响应，返回304。 快速，发送数据少，只返回一些基本响应头信息，数据量小，不发送实际响应体。</li>
<li>200 OK： 以上两种缓存都失败</li>
</ul>

<h2 id="toc_1">200 from cache 本地缓存相关Header</h2>

<p><strong>Pragma</strong>： HTTP1.0,该字段被设置为no-cache时，会告知浏览器禁用本地缓存，每次都想服务器发送请求。</p>

<p><strong>Expires</strong>： 值形如：Thu，31 Dec格林威治时间，告诉浏览器缓存实现的时刻，标记缓存有效，无需发送请求。</p>

<p><strong>Cache-Control</strong>： </p>

<ul>
<li>no-store： 禁止浏览器缓存响应</li>
<li>no-cache： 不允许直接使用本地缓存，先发起请求和服务器协商</li>
<li>max-age=delta-secondes: 告知浏览器该请求响应本地缓存有效的最长期限，以秒为单位。</li>
</ul>

<p>优先级： Pragma &gt; Cache-Control &gt; Expires</p>

<h2 id="toc_2">304 协商缓存相关Header</h2>

<p><strong>Last-Modified</strong>： 通知浏览器资源的最后修改时间</p>

<p><strong>ETag</strong>： HTTP1.1退出，文件的指纹标识符，如果文件内容修改，指纹会改变</p>

<p><strong>IF-None-Match</strong>： 本地缓存失效，会携带去请求服务端，服务端判断资源是否改变，没有则直接使用本地缓存，返回304</p>

<h2 id="toc_3">适合缓存的内容：</h2>

<p>图片、css</p>

<h2 id="toc_4">使用协商缓存</h2>

<p>HTML文件<br/>
js、css文件的加载可以加入文件签名拒绝缓存<br/>
index.css?签名<br/>
index.签名.js</p>

<h2 id="toc_5">Nginx配置缓存策略</h2>

<p>本地缓存配置<br/>
add_header指令： 添加状态码2XX和3XX的响应头信息<br/>
add_header name value [always];<br/>
可以设置Pragma、Expires、Cache-Control 可以继承</p>

<p>gzip 压缩</p>

<pre><code class="language-text">gzip on
gzip_buffers 32 4k|16 8K #内存中缓冲几块 大小
gzip_comp_level [1-9] #推荐6 压缩级别（级别越高，浪费CPU计算资源）
gzip_min_length 200 #开始压缩的最小长度
gzip_http_version 1.0|1.1
gzip_proxied  #设置请求者代理服务器，该如何缓存内容
gzip_types text/plain applicatin/xml #对那些类型的文件压缩
gzip_vary on|off  #是否传输gzip压缩标识


</code></pre>

<h2 id="toc_6">自动化压缩</h2>

<p>Grunt</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[减少HTTP请求]]></title>
    <link href="blog.lilaiqun.com/15700996704794.html"/>
    <updated>2019-10-03T18:47:50+08:00</updated>
    <id>blog.lilaiqun.com/15700996704794.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">为什么要减少？</h2>

<p>80%的时间花在html文档所引用的组件（图片、css、script等）进行的HTTP请求上。</p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">HTTP链接产生的开销</h2>

<p>域名解析、TCP连接、发送请求、等待、下载资源、解析时间</p>

<p><strong>图片地图</strong></p>

<pre><code class="language-text">&lt;img usemap=&quot;#map1&quot;&gt;
&lt;map name=&quot;map1&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;HOME&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;GIFT&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;Cart&quot;&gt;
    &lt;area shap=&quot;rect&quot; coords=&quot;0,0,31,31&quot; href=&quot;&quot; title=&quot;HELP&quot;&gt;

&lt;/map&gt;
</code></pre>

<p><strong>css精灵</strong></p>

<p>background-position属性</p>

<p><strong>合并js脚本和样式表</strong></p>

<p><strong>使用Base64编码减少页面请求数</strong></p>

<p>通过Base64编码方式将图片直接嵌入网页中</p>

<pre><code class="language-text">&lt;img src=&quot;data:image/gif;base64,/...&quot;&gt;
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web资源防盗链]]></title>
    <link href="blog.lilaiqun.com/15700981798015.html"/>
    <updated>2019-10-03T18:22:59+08:00</updated>
    <id>blog.lilaiqun.com/15700981798015.html</id>
    <content type="html"><![CDATA[
<p>常见的就是小站盗用大站的图片、音乐、视频、软件的资源<br/>
通过盗链的方法可以减轻自己服务器的负担，真实空间来自别人的服务器</p>

<p>工作原理：<br/>
通过Referer或者签名计算（规定的加密数字）</p>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1.通过Nginx配置</h2>

<p>Nginx模块 ngx_http_referer_module 用来阻挡来源非法的域名请求<br/>
Nginx指令 valid_referers, 全局变量$invalid_referer </p>

<pre><code class="language-text">valid_referers none | blocked | server_names | string;

// 参数详情：
none: &quot;Referer&quot; 来源头部为空的情况
blocked: &quot;Referer&quot; 来源头部不为空，但是里面的值被代理或防火墙删除了，这些值都不以http:// https://开头
server_names:  &quot;Referer&quot; 来源头部包含当前的server_names
</code></pre>

<p>简单示例：</p>

<pre><code class="language-text">location ~ .*\.(gif|jpg|png|flv|swf|rar|zip)$
{
    valid_referers none blocked lilaiqun.com *.lilaiqun.com;
    if ($invalid_referer) 
    {
        #return 403;
        rewite ^/ http://www.lilaiqun.com/403.jpg;
    }
}
</code></pre>

<h2 id="toc_1">2.使用加密签名</h2>

<p>使用第三方模块HttpAccessKeyModule实现Nginx防盗链<br/>
accesskey on|off 模块开关<br/>
accesskey_hashmethod md5|sha-1 签名加密方式<br/>
accesskey_arg GET参数名称<br/>
accesskey_signature 加密规则</p>

<pre><code class="language-text">location ~ .*\.(gif|jpg|png|flv|swf|rar|zip)$
{
    accesskey on;
    accesskey_hashmethod md5;
    accesskey_arg &quot;key&quot;;
    accesskey_signature &quot;mypass$remote_addr&quot;;
}
</code></pre>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[高并发结构]]></title>
    <link href="blog.lilaiqun.com/15700944894509.html"/>
    <updated>2019-10-03T17:21:29+08:00</updated>
    <id>blog.lilaiqun.com/15700944894509.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>并发：相同时间点，有多少个访问同时到来。一个系统日PV在千万以上，有可能是一个高并发系统<br/>
QPS：每秒钟请求或者查询的数量，每秒响应的请求量<br/>
吞吐量：单位时间内处理的请求数量</p>
</blockquote>

<h2 id="toc_0">高并发的问题，我们具体该关心什么？</h2>

<p>（总PV数 * 0.8）/ (6*3600 * 0.2) = 峰值每秒请求数（QPS）<br/>
80%的访问量集中在20%的时间</p>

<h2 id="toc_1">高并发解决方案案例</h2>

<p>流量优化： <a href="15700981798015.html">Web资源防盗链</a><br/>
前端优化： <a href="15700996704794.html">减少HTTP请求</a>、添加异步请求、<a href="15701010542234.html">浏览器缓存和数据压缩</a>、CDN加速、建立图片服务器<br/>
服务端优化： <a href="15701041292991.html">页面静态化</a>、并发处理（多线程异步、队列异步处理）<br/>
数据库优化： <a href="15701558070255.html">数据库缓存</a>、分库分表、分区操作、读写分离<br/>
Web服务器优化： 负载均衡</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何解决消息队列中的延迟]]></title>
    <link href="blog.lilaiqun.com/15700896906629.html"/>
    <updated>2019-10-03T16:01:30+08:00</updated>
    <id>blog.lilaiqun.com/15700896906629.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问： 如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">面试官心里分析</h2>

<p>你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了，或者消费的极其极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是整个这就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如rabbitmq设置了消息过期时间后就没了怎么办？</p>

<p>所以就这事儿，其实线上挺常见的，一般不出，一出就是大case，一般常见于，举个例子，消费端每次消费之后要写mysql，结果mysql挂了，消费端hang那儿了，不动了。或者是消费端出了个什么叉子，导致消费速度极其慢。</p>

<h2 id="toc_1">面试题分析</h2>

<p>关于这个事儿，我们一个一个来梳理吧，先假设一个场景，我们现在消费端出故障了，然后大量消息在mq里积压，现在事故了，慌了</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息的顺序性？]]></title>
    <link href="blog.lilaiqun.com/15700882317067.html"/>
    <updated>2019-10-03T15:37:11+08:00</updated>
    <id>blog.lilaiqun.com/15700882317067.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问：如何保证消息的顺序性</p>
</blockquote>

<span id="more"></span><!-- more -->

<h2 id="toc_0">面试题剖析：</h2>

<p>我举个例子，我们以前做过一个mysql binlog同步的系统，压力还是非常大的，日同步数据要达到上亿。mysql -&gt; mysql，常见的一点在于说大数据team，就需要同步一个mysql库过来，对公司的业务系统的数据做各种复杂的操作。</p>

<p>你在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。</p>

<p>本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。</p>

<p>先看看顺序会错乱的俩场景</p>

<p>（1）rabbitmq：一个queue，多个consumer，这不明显乱了<br/>
（2）kafka：一个topic，一个partition，一个consumer，<strong>内部多线程</strong>，这不也明显乱了</p>

<p><img src="http://images.lilaiqun.com/15700893668371.jpg" alt="kafka消息错乱"/></p>

<p>那如何保证消息的顺序性呢？简单简单</p>

<p>（1）rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理</p>

<p>（2）kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可</p>

<p><img src="http://images.lilaiqun.com/15700892292208.jpg" alt="kafka消息错乱解决方案"/></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息队列的可靠性（消息不丢）]]></title>
    <link href="blog.lilaiqun.com/15700740718336.html"/>
    <updated>2019-10-03T11:41:11+08:00</updated>
    <id>blog.lilaiqun.com/15700740718336.html</id>
    <content type="html"><![CDATA[
<blockquote>
<p>提问： 如何保证消息的可靠性传输（如何处理消息丢失的问题）？</p>
</blockquote>

<span id="more"></span><!-- more -->

<p>如果说你这个是用mq来传递非常核心的消息，比如说计费，扣费的一些消息，因为我以前设计和研发过一个公司非常核心的广告平台，计费系统，计费系统是很重的一个业务，操作是很耗时的。所以说广告系统整体的架构里面，实际上是将计费做成异步化的，然后中间就是加了一个MQ。</p>

<p>我们当时为了确保说这个MQ传递过程中绝对不会把计费消息给弄丢，花了很多的精力。广告主投放了一个广告，明明说好了，用户点击一次扣费1块钱。结果要是用户动不动点击了一次，扣费的时候搞的消息丢了，我们公司就会不断的少几块钱，几块钱，积少成多，这个就对公司是一个很大的损失。</p>

<h2 id="toc_0">面试题剖析</h2>

<p>这个丢数据，mq一般分为两种，要么是mq自己弄丢了，要么是我们消费的时候弄丢了。咱们从rabbitmq和kafka分别来分析一下吧</p>

<p>rabbitmq这种mq，一般来说都是承载公司的核心业务的，数据是绝对不能弄丢的</p>

<h3 id="toc_1">1.Rabbitmq</h3>

<p><img src="http://images.lilaiqun.com/15700881424752.jpg" alt=""/></p>

<p>1）生产者弄丢了数据</p>

<p>生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。</p>

<p>此时可以选择用rabbitmq提供的事务功能，就是生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。</p>

<p>所以一般来说，如果你要确保说写rabbitmq的消息别丢，可以开启confirm模式，在生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。</p>

<p>事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了。</p>

<p>所以一般在生产者这块避免数据丢失，都是用confirm机制的。</p>

<p>2）rabbitmq弄丢了数据</p>

<p>就是rabbitmq自己弄丢了数据，这个你必须开启rabbitmq的持久化，就是消息写入之后会持久化到磁盘，哪怕是rabbitmq自己挂了，恢复之后会自动读取之前存储的数据，一般数据不会丢。除非极其罕见的是，rabbitmq还没持久化，自己就挂了，可能导致少量数据会丢失的，但是这个概率较小。</p>

<p>设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，也会从磁盘上重启恢复queue，恢复这个queue里的数据。</p>

<p>而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。</p>

<p>哪怕是你给rabbitmq开启了持久化机制，也有一种可能，就是这个消息写到了rabbitmq中，但是还没来得及持久化到磁盘上，结果不巧，此时rabbitmq挂了，就会导致内存里的一点点数据会丢失。</p>

<p>3）消费端弄丢了数据</p>

<p>rabbitmq如果丢失了数据，主要是因为你消费的时候，刚消费到，还没处理，结果进程挂了，比如重启了，那么就尴尬了，rabbitmq认为你都消费了，这数据就丢了。</p>

<p>这个时候得用rabbitmq提供的ack机制，简单来说，就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。</p>

<h3 id="toc_2">2.kafka</h3>

<p><img src="http://images.lilaiqun.com/15700881304080.jpg" alt=""/></p>

<p>1）消费端弄丢了数据</p>

<p>唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。</p>

<p>这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。</p>

<p>生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。</p>

<p>然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了</p>

<p>2）kafka弄丢了数据</p>

<p>这块比较常见的一个场景，就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。</p>

<p>生产环境也遇到过，我们也是，之前kafka的leader机器宕机了，将follower切换为leader之后，就会发现说这个数据就丢了</p>

<p>所以此时一般是要求起码设置如下4个参数：</p>

<p>给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本</p>

<p>在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧</p>

<p>在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了</p>

<p>在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了</p>

<p>我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失</p>

<p>3）生产者会不会弄丢数据</p>

<p>如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，所有的follower都同步到了消息之后，才认为本次写成功了。如果没满足这个条件，生产者会自动不断的重试，重试无限次。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息不被重复消费（消费时的幂等性）]]></title>
    <link href="blog.lilaiqun.com/15700210659906.html"/>
    <updated>2019-10-02T20:57:45+08:00</updated>
    <id>blog.lilaiqun.com/15700210659906.html</id>
    <content type="html"><![CDATA[
<span id="more"></span><!-- more -->

<p><img src="http://images.lilaiqun.com/%E5%9B%BE%E7%89%87.png" alt="Kafka图示"/><br/>
<img src="http://images.lilaiqun.com/15700216386343.jpg" alt=""/></p>

<p>回答这个问题，首先你别听到重复消息这个事儿，就一无所知吧，你先大概说一说可能会有哪些重复消费的问题。</p>

<p>首先就是比如rabbitmq、rocketmq、kafka，都有可能会出现消费重复消费的问题，正常。因为这问题通常不是mq自己保证的，是给你保证的。然后我们挑一个kafka来举个例子，说说怎么重复消费吧。</p>

<p>kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。</p>

<p>但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。</p>

<p><strong>其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。</strong></p>

<p>给你举个例子吧。假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，不就保留了一条数据？</p>

<p>一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性</p>

<p>幂等性，我通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。</p>

<p>那所以第二个问题来了，怎么保证消息队列消费的幂等性？</p>

<p>其实还是得结合业务来思考，我这里给几个思路：</p>

<p>（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧</p>

<p>（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性</p>

<p>（3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。</p>

<p>还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据</p>

<p>如何保证MQ的消费是幂等性的，需要结合具体的业务来看</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[如何保证消息队列的高可用啊？]]></title>
    <link href="blog.lilaiqun.com/15700185588826.html"/>
    <updated>2019-10-02T20:15:58+08:00</updated>
    <id>blog.lilaiqun.com/15700185588826.html</id>
    <content type="html"><![CDATA[
<p>问题：</p>

<pre><code class="language-text">MQ的缺点：系统可用性降低。接下来围绕MQ的缺点怎么解决。

MQ的高可用性怎么保证？ 
</code></pre>

<span id="more"></span><!-- more -->

<h2 id="toc_0">1. RabbitMQ的高可用</h2>

<p>RabbitMQ比较有代表性，因为是基于主从架构</p>

<p>3种模式：<strong>单机模式，普通集群模式，镜像集群模式</strong></p>

<p>1）单机模式</p>

<p>就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式</p>

<p>2）普通集群模式</p>

<p><img src="http://images.lilaiqun.com/15700196661169.jpg" alt=""/></p>

<p>意思就是在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。</p>

<p>这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。</p>

<p>而且如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。</p>

<p>所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作。</p>

<p>3）镜像集群模式</p>

<p><img src="http://images.lilaiqun.com/15700197102596.jpg" alt=""/></p>

<p>这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。</p>

<p>这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue</p>

<p>那么怎么开启这个镜像集群模式呢？我这里简单说一下，避免面试人家问你你不知道，其实很简单rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。</p>

<h2 id="toc_1">2. kakfa</h2>

<p><img src="http://images.lilaiqun.com/15700200076415.jpg" alt=""/></p>

<p>kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。</p>

<p>这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。</p>

<p>实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。</p>

<p>kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。</p>

<p>kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。</p>

<p>这么搞，就有所谓的高可用性了，因为如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。</p>

<p>写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）</p>

<p>消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。</p>

<p>实际上这块机制，讲深了，是可以非常之深入的，但是我还是回到我们这个课程的主题和定位，聚焦面试，至少你听到这里大致明白了kafka是如何保证高可用机制的了，对吧？不至于一无所知，现场还能给面试官画画图。要遇上面试官确实是kafka高手，深挖了问，那你只能说不好意思，太深入的你没研究过。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[消息队列技术选型]]></title>
    <link href="blog.lilaiqun.com/15700030762829.html"/>
    <updated>2019-10-02T15:57:56+08:00</updated>
    <id>blog.lilaiqun.com/15700030762829.html</id>
    <content type="html"><![CDATA[
<h2 id="toc_0">1.为何使用消息队列</h2>

<p><code>解耦、异步、消峰</code></p>

<span id="more"></span><!-- more -->

<h2 id="toc_1">2.缺点</h2>

<ol>
<li>可用性降低，系统太依赖消息队列<br/></li>
<li>增加系统复杂性，发送多次消息<br/></li>
<li>一致性问题，消息发送顺序错误，导致结果错误<br/></li>
</ol>

<table>
<thead>
<tr>
<th></th>
<th>ActiveMQ</th>
<th>RabbitMQ</th>
<th>RocketMQ</th>
<th>Kafka</th>
</tr>
</thead>

<tbody>
<tr>
<td>吞吐量</td>
<td>万级</td>
<td>万级</td>
<td>10万级</td>
<td>10万级</td>
</tr>
<tr>
<td>topic数量对吞吐量影响</td>
<td>万级</td>
<td>万级</td>
<td>topic可以达到几千级别，吞吐量会小幅度下降</td>
<td>topic从几十到几百个的时候，吞吐量会大幅度下降。 所以同等机器下，kafka尽量保证topic数量不要过多</td>
</tr>
<tr>
<td>时效性</td>
<td>ms级</td>
<td>微妙级，延迟最低</td>
<td>ms级</td>
<td>ms以内</td>
</tr>
<tr>
<td>可用性</td>
<td>搞，基于主从架构实现高可用</td>
<td>高，基于主从架构</td>
<td>非常高，分布式</td>
<td>非常高，分布式，一个数据多个副本，不会丢失数据</td>
</tr>
<tr>
<td>消息可靠性</td>
<td>低概率丢失</td>
<td></td>
<td>通过参数优化配置，0丢失</td>
<td>通过参数优化配置，0丢失</td>
</tr>
<tr>
<td>功能支持</td>
<td>MQ功能极其完备</td>
<td>自带后台适合小型公司，社区活跃，基于erlang开发，开发能力强，延迟很低</td>
<td>MQ功能比较完善，还是分布式的，扩展性好</td>
<td>支持简单MQ功能，在大数据领域的实时计算以及日志采集被大规模使用</td>
</tr>
<tr>
<td>优劣势</td>
<td>非常成熟，功能强大</td>
<td>erlang开发，性能好，延迟低</td>
<td>接口简单</td>
<td>吞吐量搞，大数据领域的日志采集</td>
</tr>
</tbody>
</table>

<h2 id="toc_2">RabbitMq</h2>

<h2 id="toc_3">MQ</h2>

<h2 id="toc_4">Redis</h2>

<h2 id="toc_5">Kafka</h2>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[目录接口]]></title>
    <link href="blog.lilaiqun.com/15700028122851.html"/>
    <updated>2019-10-02T15:53:32+08:00</updated>
    <id>blog.lilaiqun.com/15700028122851.html</id>
    <content type="html"><![CDATA[
<p>编译与执行<br/>
词法、语法分析基本原理<br/>
抽象语法书<br/>
Zend虚拟机</p>

<h2 id="toc_0">基本语法与扩展编写</h2>

<p><a href="#">各类基础语法的实现</a><br/>
<a href="#">手把手编写一个PHP扩展</a></p>

]]></content>
  </entry>
  
</feed>
